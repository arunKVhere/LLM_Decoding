{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# LLM Decoding from Scratch\n",
        "\n",
        "This notebook demonstrates how to implement text generation decoding strategies from scratch using a real language model (GPT-2 small).\n",
        "\n",
        "## What We'll Build\n",
        "\n",
        "| Strategy | Description | Use Case |\n",
        "|----------|-------------|----------|\n",
        "| **Greedy** | Always pick highest probability token | Deterministic, fast |\n",
        "| **Temperature** | Scale logits before softmax | Control randomness |\n",
        "| **Top-p (Nucleus)** | Sample from smallest set with cumulative p | Dynamic vocabulary |\n",
        "| **Beam Search** | Track multiple candidates | Higher quality |\n",
        "\n",
        "---\n",
        "\n",
        "## Key Insight: LLMs Only Predict Next Token\n",
        "\n",
        "```\n",
        "Input: \"The cat sat on the\"\n",
        "                          ↓\n",
        "              [LLM computes logits]\n",
        "                          ↓\n",
        "         logits = [2.1, -0.5, 3.2, ...] (vocab_size)\n",
        "                          ↓\n",
        "              [Apply decoding strategy]\n",
        "                          ↓\n",
        "                  Next token: \"mat\"\n",
        "```\n",
        "\n",
        "The **decoding strategy** is how we convert logits → next token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8eky370tr3g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8eky370tr3g",
        "outputId": "1ffe3850-ff66-42e7-cbb8-c7a0d23f3e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: transformers==4.46.0 in /usr/local/lib/python3.12/dist-packages (4.46.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (3.20.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (0.7.0)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.0) (2026.1.4)\n",
            "Package                                  Version\n",
            "---------------------------------------- ------------------\n",
            "absl-py                                  1.4.0\n",
            "accelerate                               1.12.0\n",
            "access                                   1.1.10.post3\n",
            "affine                                   2.4.0\n",
            "aiofiles                                 24.1.0\n",
            "aiohappyeyeballs                         2.6.1\n",
            "aiohttp                                  3.13.3\n",
            "aiosignal                                1.4.0\n",
            "aiosqlite                                0.22.1\n",
            "alabaster                                1.0.0\n",
            "albucore                                 0.0.24\n",
            "albumentations                           2.0.8\n",
            "ale-py                                   0.11.2\n",
            "alembic                                  1.17.2\n",
            "altair                                   5.5.0\n",
            "annotated-doc                            0.0.4\n",
            "annotated-types                          0.7.0\n",
            "antlr4-python3-runtime                   4.9.3\n",
            "anyio                                    4.12.1\n",
            "anywidget                                0.9.21\n",
            "apsw                                     3.51.1.0\n",
            "apswutils                                0.1.2\n",
            "argon2-cffi                              25.1.0\n",
            "argon2-cffi-bindings                     25.1.0\n",
            "array_record                             0.8.3\n",
            "arrow                                    1.4.0\n",
            "arviz                                    0.22.0\n",
            "astropy                                  7.2.0\n",
            "astropy-iers-data                        0.2026.1.5.0.43.43\n",
            "astunparse                               1.6.3\n",
            "atpublic                                 5.1\n",
            "attrs                                    25.4.0\n",
            "audioread                                3.1.0\n",
            "Authlib                                  1.6.6\n",
            "autograd                                 1.8.0\n",
            "babel                                    2.17.0\n",
            "backcall                                 0.2.0\n",
            "beartype                                 0.22.9\n",
            "beautifulsoup4                           4.13.5\n",
            "betterproto                              2.0.0b6\n",
            "bigframes                                2.31.0\n",
            "bigquery-magics                          0.10.3\n",
            "bleach                                   6.3.0\n",
            "blinker                                  1.9.0\n",
            "blis                                     1.3.3\n",
            "blobfile                                 3.1.0\n",
            "blosc2                                   3.12.2\n",
            "bokeh                                    3.7.3\n",
            "Bottleneck                               1.4.2\n",
            "bqplot                                   0.12.45\n",
            "branca                                   0.8.2\n",
            "brotli                                   1.2.0\n",
            "CacheControl                             0.14.4\n",
            "cachetools                               6.2.4\n",
            "catalogue                                2.0.10\n",
            "certifi                                  2026.1.4\n",
            "cffi                                     2.0.0\n",
            "chardet                                  5.2.0\n",
            "charset-normalizer                       3.4.4\n",
            "chex                                     0.1.90\n",
            "clarabel                                 0.11.1\n",
            "click                                    8.3.1\n",
            "click-plugins                            1.1.1.2\n",
            "cligj                                    0.7.2\n",
            "cloudpathlib                             0.23.0\n",
            "cloudpickle                              3.1.2\n",
            "cmake                                    3.31.10\n",
            "cmdstanpy                                1.3.0\n",
            "colorcet                                 3.1.0\n",
            "colorlover                               0.3.0\n",
            "colour                                   0.1.5\n",
            "community                                1.0.0b1\n",
            "confection                               0.1.5\n",
            "cons                                     0.4.7\n",
            "contourpy                                1.3.3\n",
            "cramjam                                  2.11.0\n",
            "cryptography                             43.0.3\n",
            "cufflinks                                0.17.3\n",
            "curl_cffi                                0.14.0\n",
            "cvxopt                                   1.3.2\n",
            "cvxpy                                    1.6.7\n",
            "cycler                                   0.12.1\n",
            "cyipopt                                  1.5.0\n",
            "cymem                                    2.0.13\n",
            "Cython                                   3.0.12\n",
            "dask                                     2025.12.0\n",
            "dataproc-spark-connect                   1.0.1\n",
            "datasets                                 4.0.0\n",
            "db-dtypes                                1.5.0\n",
            "dbus-python                              1.2.18\n",
            "debugpy                                  1.8.15\n",
            "decorator                                4.4.2\n",
            "defusedxml                               0.7.1\n",
            "deprecation                              2.1.0\n",
            "diffusers                                0.36.0\n",
            "dill                                     0.3.8\n",
            "distro                                   1.9.0\n",
            "dlib                                     19.24.6\n",
            "dm-tree                                  0.1.9\n",
            "docstring_parser                         0.17.0\n",
            "docutils                                 0.21.2\n",
            "dopamine_rl                              4.1.2\n",
            "duckdb                                   1.3.2\n",
            "earthengine-api                          1.5.24\n",
            "easydict                                 1.13\n",
            "editdistance                             0.8.1\n",
            "eerepr                                   0.1.2\n",
            "einops                                   0.8.1\n",
            "en_core_web_sm                           3.8.0\n",
            "entrypoints                              0.4\n",
            "esda                                     2.8.1\n",
            "et_xmlfile                               2.0.0\n",
            "etils                                    1.13.0\n",
            "etuples                                  0.3.10\n",
            "Farama-Notifications                     0.0.4\n",
            "fastai                                   2.8.6\n",
            "fastapi                                  0.123.10\n",
            "fastcore                                 1.11.2\n",
            "fastdownload                             0.0.7\n",
            "fastjsonschema                           2.21.2\n",
            "fastlite                                 0.2.3\n",
            "fastprogress                             1.1.3\n",
            "fasttransform                            0.0.2\n",
            "ffmpy                                    1.0.0\n",
            "filelock                                 3.20.2\n",
            "fiona                                    1.10.1\n",
            "firebase-admin                           6.9.0\n",
            "Flask                                    3.1.2\n",
            "flatbuffers                              25.12.19\n",
            "flax                                     0.10.7\n",
            "folium                                   0.20.0\n",
            "fonttools                                4.61.1\n",
            "fqdn                                     1.5.1\n",
            "frozendict                               2.4.7\n",
            "frozenlist                               1.8.0\n",
            "fsspec                                   2025.3.0\n",
            "future                                   1.0.0\n",
            "gast                                     0.7.0\n",
            "gcsfs                                    2025.3.0\n",
            "GDAL                                     3.8.4\n",
            "gdown                                    5.2.0\n",
            "geemap                                   0.35.3\n",
            "geocoder                                 1.38.1\n",
            "geographiclib                            2.1\n",
            "geopandas                                1.1.2\n",
            "geopy                                    2.4.1\n",
            "giddy                                    2.3.8\n",
            "gin-config                               0.5.0\n",
            "gitdb                                    4.0.12\n",
            "GitPython                                3.1.46\n",
            "glob2                                    0.7\n",
            "google                                   3.0.0\n",
            "google-adk                               1.21.0\n",
            "google-ai-generativelanguage             0.6.15\n",
            "google-api-core                          2.29.0\n",
            "google-api-python-client                 2.187.0\n",
            "google-auth                              2.43.0\n",
            "google-auth-httplib2                     0.3.0\n",
            "google-auth-oauthlib                     1.2.2\n",
            "google-cloud-aiplatform                  1.130.0\n",
            "google-cloud-appengine-logging           1.7.0\n",
            "google-cloud-audit-log                   0.4.0\n",
            "google-cloud-bigquery                    3.40.0\n",
            "google-cloud-bigquery-connection         1.19.0\n",
            "google-cloud-bigquery-storage            2.36.0\n",
            "google-cloud-bigtable                    2.35.0\n",
            "google-cloud-core                        2.5.0\n",
            "google-cloud-dataproc                    5.23.0\n",
            "google-cloud-datastore                   2.23.0\n",
            "google-cloud-discoveryengine             0.13.12\n",
            "google-cloud-firestore                   2.22.0\n",
            "google-cloud-functions                   1.21.0\n",
            "google-cloud-language                    2.18.0\n",
            "google-cloud-logging                     3.13.0\n",
            "google-cloud-monitoring                  2.28.0\n",
            "google-cloud-resource-manager            1.15.0\n",
            "google-cloud-secret-manager              2.26.0\n",
            "google-cloud-spanner                     3.61.0\n",
            "google-cloud-speech                      2.35.0\n",
            "google-cloud-storage                     3.7.0\n",
            "google-cloud-trace                       1.17.0\n",
            "google-cloud-translate                   3.23.0\n",
            "google-colab                             1.0.0\n",
            "google-crc32c                            1.8.0\n",
            "google-genai                             1.55.0\n",
            "google-generativeai                      0.8.6\n",
            "google-pasta                             0.2.0\n",
            "google-resumable-media                   2.8.0\n",
            "googleapis-common-protos                 1.72.0\n",
            "googledrivedownloader                    1.1.0\n",
            "gradio                                   5.50.0\n",
            "gradio_client                            1.14.0\n",
            "graphviz                                 0.21\n",
            "greenlet                                 3.3.0\n",
            "groovy                                   0.1.2\n",
            "grpc-google-iam-v1                       0.14.3\n",
            "grpc-interceptor                         0.15.4\n",
            "grpcio                                   1.76.0\n",
            "grpcio-status                            1.71.2\n",
            "grpclib                                  0.4.9\n",
            "gspread                                  6.2.1\n",
            "gspread-dataframe                        4.0.0\n",
            "gym                                      0.25.2\n",
            "gym-notices                              0.1.0\n",
            "gymnasium                                1.2.3\n",
            "h11                                      0.16.0\n",
            "h2                                       4.3.0\n",
            "h5netcdf                                 1.7.3\n",
            "h5py                                     3.15.1\n",
            "hdbscan                                  0.8.41\n",
            "hf_transfer                              0.1.9\n",
            "hf-xet                                   1.2.0\n",
            "highspy                                  1.12.0\n",
            "holidays                                 0.88\n",
            "holoviews                                1.22.1\n",
            "hpack                                    4.1.0\n",
            "html5lib                                 1.1\n",
            "httpcore                                 1.0.9\n",
            "httpimport                               1.4.1\n",
            "httplib2                                 0.31.0\n",
            "httptools                                0.7.1\n",
            "httpx                                    0.28.1\n",
            "httpx-sse                                0.4.3\n",
            "huggingface-hub                          0.36.0\n",
            "humanize                                 4.15.0\n",
            "hyperframe                               6.1.0\n",
            "hyperopt                                 0.2.7\n",
            "ibis-framework                           9.5.0\n",
            "idna                                     3.11\n",
            "ImageIO                                  2.37.2\n",
            "imageio-ffmpeg                           0.6.0\n",
            "imagesize                                1.4.1\n",
            "imbalanced-learn                         0.14.1\n",
            "immutabledict                            4.2.2\n",
            "importlib_metadata                       8.7.1\n",
            "importlib_resources                      6.5.2\n",
            "imutils                                  0.5.4\n",
            "inequality                               1.1.2\n",
            "inflect                                  7.5.0\n",
            "iniconfig                                2.3.0\n",
            "intel-cmplr-lib-ur                       2025.3.1\n",
            "intel-openmp                             2025.3.1\n",
            "ipyevents                                2.0.4\n",
            "ipyfilechooser                           0.6.0\n",
            "ipykernel                                6.17.1\n",
            "ipyleaflet                               0.20.0\n",
            "ipyparallel                              8.8.0\n",
            "ipython                                  7.34.0\n",
            "ipython-genutils                         0.2.0\n",
            "ipython-sql                              0.5.0\n",
            "ipytree                                  0.2.2\n",
            "ipywidgets                               7.7.1\n",
            "isoduration                              20.11.0\n",
            "itsdangerous                             2.2.0\n",
            "jaraco.classes                           3.4.0\n",
            "jaraco.context                           6.0.2\n",
            "jaraco.functools                         4.4.0\n",
            "jax                                      0.7.2\n",
            "jaxlib                                   0.7.2\n",
            "jeepney                                  0.9.0\n",
            "jieba                                    0.42.1\n",
            "Jinja2                                   3.1.6\n",
            "jiter                                    0.12.0\n",
            "joblib                                   1.5.3\n",
            "jsonpatch                                1.33\n",
            "jsonpickle                               4.1.1\n",
            "jsonpointer                              3.0.0\n",
            "jsonschema                               4.26.0\n",
            "jsonschema-specifications                2025.9.1\n",
            "jupyter_client                           7.4.9\n",
            "jupyter-console                          6.6.3\n",
            "jupyter_core                             5.9.1\n",
            "jupyter-events                           0.12.0\n",
            "jupyter_kernel_gateway                   2.5.2\n",
            "jupyter-leaflet                          0.20.0\n",
            "jupyter_server                           2.14.0\n",
            "jupyter_server_terminals                 0.5.3\n",
            "jupyterlab_pygments                      0.3.0\n",
            "jupyterlab_widgets                       3.0.16\n",
            "jupytext                                 1.18.1\n",
            "kaggle                                   1.7.4.5\n",
            "kagglehub                                0.3.13\n",
            "keras                                    3.10.0\n",
            "keras-hub                                0.21.1\n",
            "keras-nlp                                0.21.1\n",
            "keyring                                  25.7.0\n",
            "keyrings.google-artifactregistry-auth    1.1.2\n",
            "kiwisolver                               1.4.9\n",
            "langchain                                1.2.3\n",
            "langchain-core                           1.2.6\n",
            "langgraph                                1.0.5\n",
            "langgraph-checkpoint                     3.0.1\n",
            "langgraph-prebuilt                       1.0.5\n",
            "langgraph-sdk                            0.3.1\n",
            "langsmith                                0.6.1\n",
            "lark                                     1.3.1\n",
            "launchpadlib                             1.10.16\n",
            "lazr.restfulclient                       0.14.4\n",
            "lazr.uri                                 1.0.6\n",
            "lazy_loader                              0.4\n",
            "libclang                                 18.1.1\n",
            "libpysal                                 4.14.0\n",
            "librosa                                  0.11.0\n",
            "lightgbm                                 4.6.0\n",
            "linkify-it-py                            2.0.3\n",
            "llvmlite                                 0.43.0\n",
            "locket                                   1.0.0\n",
            "logical-unification                      0.4.7\n",
            "lxml                                     6.0.2\n",
            "Mako                                     1.3.10\n",
            "mapclassify                              2.10.0\n",
            "Markdown                                 3.10\n",
            "markdown-it-py                           4.0.0\n",
            "MarkupSafe                               3.0.3\n",
            "matplotlib                               3.10.0\n",
            "matplotlib-inline                        0.2.1\n",
            "matplotlib-venn                          1.1.2\n",
            "mcp                                      1.25.0\n",
            "mdit-py-plugins                          0.5.0\n",
            "mdurl                                    0.1.2\n",
            "mgwr                                     2.2.1\n",
            "miniKanren                               1.0.5\n",
            "missingno                                0.5.2\n",
            "mistune                                  3.2.0\n",
            "mizani                                   0.13.5\n",
            "mkl                                      2025.3.0\n",
            "ml_dtypes                                0.5.4\n",
            "mlxtend                                  0.23.4\n",
            "mmh3                                     5.2.0\n",
            "momepy                                   0.11.0\n",
            "more-itertools                           10.8.0\n",
            "moviepy                                  1.0.3\n",
            "mpmath                                   1.3.0\n",
            "msgpack                                  1.1.2\n",
            "multidict                                6.7.0\n",
            "multipledispatch                         1.0.0\n",
            "multiprocess                             0.70.16\n",
            "multitasking                             0.0.12\n",
            "murmurhash                               1.0.15\n",
            "music21                                  9.9.1\n",
            "namex                                    0.1.0\n",
            "narwhals                                 2.15.0\n",
            "natsort                                  8.4.0\n",
            "nbclassic                                1.3.3\n",
            "nbclient                                 0.10.4\n",
            "nbconvert                                7.16.6\n",
            "nbformat                                 5.10.4\n",
            "ndindex                                  1.10.1\n",
            "nest-asyncio                             1.6.0\n",
            "networkx                                 3.6.1\n",
            "nibabel                                  5.3.3\n",
            "nltk                                     3.9.1\n",
            "notebook                                 6.5.7\n",
            "notebook_shim                            0.2.4\n",
            "numba                                    0.60.0\n",
            "numexpr                                  2.14.1\n",
            "numpy                                    2.0.2\n",
            "nvidia-nccl-cu12                         2.29.2\n",
            "oauth2client                             4.1.3\n",
            "oauthlib                                 3.3.1\n",
            "omegaconf                                2.3.0\n",
            "onemkl-license                           2025.3.0\n",
            "openai                                   2.14.0\n",
            "opencv-contrib-python                    4.12.0.88\n",
            "opencv-python                            4.12.0.88\n",
            "opencv-python-headless                   4.12.0.88\n",
            "openpyxl                                 3.1.5\n",
            "opentelemetry-api                        1.37.0\n",
            "opentelemetry-exporter-gcp-logging       1.11.0a0\n",
            "opentelemetry-exporter-gcp-monitoring    1.11.0a0\n",
            "opentelemetry-exporter-gcp-trace         1.11.0\n",
            "opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "opentelemetry-exporter-otlp-proto-http   1.37.0\n",
            "opentelemetry-proto                      1.37.0\n",
            "opentelemetry-resourcedetector-gcp       1.11.0a0\n",
            "opentelemetry-sdk                        1.37.0\n",
            "opentelemetry-semantic-conventions       0.58b0\n",
            "opt_einsum                               3.4.0\n",
            "optax                                    0.2.6\n",
            "optree                                   0.18.0\n",
            "orbax-checkpoint                         0.11.31\n",
            "orjson                                   3.11.5\n",
            "ormsgpack                                1.12.1\n",
            "osqp                                     1.0.5\n",
            "overrides                                7.7.0\n",
            "packaging                                25.0\n",
            "pandas                                   2.2.2\n",
            "pandas-datareader                        0.10.0\n",
            "pandas-gbq                               0.30.0\n",
            "pandas-stubs                             2.2.2.240909\n",
            "pandocfilters                            1.5.1\n",
            "panel                                    1.8.5\n",
            "param                                    2.3.1\n",
            "parso                                    0.8.5\n",
            "parsy                                    2.2\n",
            "partd                                    1.4.2\n",
            "patsy                                    1.0.2\n",
            "peewee                                   3.19.0\n",
            "peft                                     0.18.0\n",
            "pexpect                                  4.9.0\n",
            "pickleshare                              0.7.5\n",
            "pillow                                   11.3.0\n",
            "pip                                      24.1.2\n",
            "platformdirs                             4.5.1\n",
            "plotly                                   5.24.1\n",
            "plotnine                                 0.14.5\n",
            "pluggy                                   1.6.0\n",
            "plum-dispatch                            2.6.1\n",
            "ply                                      3.11\n",
            "pointpats                                2.5.2\n",
            "polars                                   1.31.0\n",
            "pooch                                    1.8.2\n",
            "portpicker                               1.5.2\n",
            "preshed                                  3.0.12\n",
            "prettytable                              3.17.0\n",
            "proglog                                  0.1.12\n",
            "progressbar2                             4.5.0\n",
            "prometheus_client                        0.23.1\n",
            "promise                                  2.3\n",
            "prompt_toolkit                           3.0.52\n",
            "propcache                                0.4.1\n",
            "prophet                                  1.2.1\n",
            "proto-plus                               1.27.0\n",
            "protobuf                                 5.29.5\n",
            "psutil                                   5.9.5\n",
            "psycopg2                                 2.9.11\n",
            "psygnal                                  0.15.1\n",
            "ptyprocess                               0.7.0\n",
            "PuLP                                     3.3.0\n",
            "py-cpuinfo                               9.0.0\n",
            "py4j                                     0.10.9.9\n",
            "pyarrow                                  18.1.0\n",
            "pyasn1                                   0.6.1\n",
            "pyasn1_modules                           0.4.2\n",
            "pycairo                                  1.29.0\n",
            "pycocotools                              2.0.11\n",
            "pycparser                                2.23\n",
            "pycryptodomex                            3.23.0\n",
            "pydantic                                 2.12.3\n",
            "pydantic_core                            2.41.4\n",
            "pydantic-settings                        2.12.0\n",
            "pydata-google-auth                       1.9.1\n",
            "pydot                                    4.0.1\n",
            "pydotplus                                2.0.2\n",
            "PyDrive2                                 1.21.3\n",
            "pydub                                    0.25.1\n",
            "pyerfa                                   2.0.1.5\n",
            "pygame                                   2.6.1\n",
            "pygit2                                   1.19.1\n",
            "Pygments                                 2.19.2\n",
            "PyGObject                                3.48.2\n",
            "PyJWT                                    2.10.1\n",
            "pymc                                     5.27.0\n",
            "pynndescent                              0.6.0\n",
            "pyogrio                                  0.12.1\n",
            "pyomo                                    6.9.5\n",
            "PyOpenGL                                 3.1.10\n",
            "pyOpenSSL                                24.2.1\n",
            "pyparsing                                3.3.1\n",
            "pyperclip                                1.11.0\n",
            "pyproj                                   3.7.2\n",
            "pysal                                    25.7\n",
            "pyshp                                    3.0.3\n",
            "PySocks                                  1.7.1\n",
            "pyspark                                  4.0.1\n",
            "pytensor                                 2.36.3\n",
            "pytest                                   8.4.2\n",
            "python-apt                               0.0.0\n",
            "python-box                               7.3.2\n",
            "python-dateutil                          2.9.0.post0\n",
            "python-dotenv                            1.2.1\n",
            "python-fasthtml                          0.12.37\n",
            "python-json-logger                       4.0.0\n",
            "python-louvain                           0.16\n",
            "python-multipart                         0.0.21\n",
            "python-slugify                           8.0.4\n",
            "python-snappy                            0.7.3\n",
            "python-utils                             3.9.1\n",
            "pytz                                     2025.2\n",
            "pyviz_comms                              3.0.6\n",
            "PyWavelets                               1.9.0\n",
            "PyYAML                                   6.0.3\n",
            "pyzmq                                    26.2.1\n",
            "quantecon                                0.10.1\n",
            "rasterio                                 1.5.0\n",
            "rasterstats                              0.20.0\n",
            "ratelim                                  0.1.6\n",
            "referencing                              0.37.0\n",
            "regex                                    2025.11.3\n",
            "requests                                 2.32.4\n",
            "requests-oauthlib                        2.0.0\n",
            "requests-toolbelt                        1.0.0\n",
            "requirements-parser                      0.9.0\n",
            "rfc3339-validator                        0.1.4\n",
            "rfc3986-validator                        0.1.1\n",
            "rfc3987-syntax                           1.1.0\n",
            "rich                                     13.9.4\n",
            "roman-numerals                           4.1.0\n",
            "roman-numerals-py                        4.1.0\n",
            "rpds-py                                  0.30.0\n",
            "rpy2                                     3.5.17\n",
            "rsa                                      4.9.1\n",
            "rtree                                    1.4.1\n",
            "ruff                                     0.14.11\n",
            "safehttpx                                0.1.7\n",
            "safetensors                              0.7.0\n",
            "scikit-image                             0.25.2\n",
            "scikit-learn                             1.6.1\n",
            "scipy                                    1.16.3\n",
            "scooby                                   0.11.0\n",
            "scs                                      3.2.10\n",
            "seaborn                                  0.13.2\n",
            "SecretStorage                            3.5.0\n",
            "segregation                              2.5.3\n",
            "semantic-version                         2.10.0\n",
            "Send2Trash                               2.0.0\n",
            "sentence-transformers                    5.2.0\n",
            "sentencepiece                            0.2.1\n",
            "sentry-sdk                               2.49.0\n",
            "setuptools                               75.2.0\n",
            "shap                                     0.50.0\n",
            "shapely                                  2.1.2\n",
            "shellingham                              1.5.4\n",
            "simple-parsing                           0.1.7\n",
            "simplejson                               3.20.2\n",
            "simsimd                                  6.5.12\n",
            "six                                      1.17.0\n",
            "sklearn-compat                           0.1.5\n",
            "sklearn-pandas                           2.2.0\n",
            "slicer                                   0.0.8\n",
            "smart_open                               7.5.0\n",
            "smmap                                    5.0.2\n",
            "sniffio                                  1.3.1\n",
            "snowballstemmer                          3.0.1\n",
            "soundfile                                0.13.1\n",
            "soupsieve                                2.8.1\n",
            "soxr                                     1.0.0\n",
            "spacy                                    3.8.11\n",
            "spacy-legacy                             3.0.12\n",
            "spacy-loggers                            1.0.5\n",
            "spaghetti                                1.7.6\n",
            "spanner-graph-notebook                   1.1.8\n",
            "spglm                                    1.1.0\n",
            "Sphinx                                   8.2.3\n",
            "sphinxcontrib-applehelp                  2.0.0\n",
            "sphinxcontrib-devhelp                    2.0.0\n",
            "sphinxcontrib-htmlhelp                   2.1.0\n",
            "sphinxcontrib-jsmath                     1.0.1\n",
            "sphinxcontrib-qthelp                     2.0.0\n",
            "sphinxcontrib-serializinghtml            2.0.0\n",
            "spint                                    1.0.7\n",
            "splot                                    1.1.7\n",
            "spopt                                    0.7.0\n",
            "spreg                                    1.8.4\n",
            "SQLAlchemy                               2.0.45\n",
            "sqlalchemy-spanner                       1.17.2\n",
            "sqlglot                                  25.20.2\n",
            "sqlparse                                 0.5.5\n",
            "srsly                                    2.5.2\n",
            "sse-starlette                            3.1.2\n",
            "stanio                                   0.5.1\n",
            "starlette                                0.50.0\n",
            "statsmodels                              0.14.6\n",
            "stringzilla                              4.6.0\n",
            "stumpy                                   1.13.0\n",
            "sympy                                    1.14.0\n",
            "tables                                   3.10.2\n",
            "tabulate                                 0.9.0\n",
            "tbb                                      2022.3.0\n",
            "tcmlib                                   1.4.1\n",
            "tenacity                                 9.1.2\n",
            "tensorboard                              2.19.0\n",
            "tensorboard-data-server                  0.7.2\n",
            "tensorflow                               2.19.0\n",
            "tensorflow-datasets                      4.9.9\n",
            "tensorflow_decision_forests              1.12.0\n",
            "tensorflow-hub                           0.16.1\n",
            "tensorflow-metadata                      1.17.2\n",
            "tensorflow-probability                   0.25.0\n",
            "tensorflow-text                          2.19.0\n",
            "tensorstore                              0.1.80\n",
            "termcolor                                3.3.0\n",
            "terminado                                0.18.1\n",
            "text-unidecode                           1.3\n",
            "textblob                                 0.19.0\n",
            "tf_keras                                 2.19.0\n",
            "tf-slim                                  1.1.0\n",
            "thinc                                    8.3.10\n",
            "threadpoolctl                            3.6.0\n",
            "tifffile                                 2025.12.20\n",
            "tiktoken                                 0.12.0\n",
            "timm                                     1.0.24\n",
            "tinycss2                                 1.4.0\n",
            "tobler                                   0.13.0\n",
            "tokenizers                               0.20.3\n",
            "toml                                     0.10.2\n",
            "tomlkit                                  0.13.3\n",
            "toolz                                    0.12.1\n",
            "torch                                    2.9.0+cpu\n",
            "torchao                                  0.10.0\n",
            "torchaudio                               2.9.0+cpu\n",
            "torchdata                                0.11.0\n",
            "torchsummary                             1.5.1\n",
            "torchtune                                0.6.1\n",
            "torchvision                              0.24.0+cpu\n",
            "tornado                                  6.5.1\n",
            "tqdm                                     4.67.1\n",
            "traitlets                                5.7.1\n",
            "traittypes                               0.2.3\n",
            "transformers                             4.46.0\n",
            "treescope                                0.1.10\n",
            "tsfresh                                  0.21.1\n",
            "tweepy                                   4.16.0\n",
            "typeguard                                4.4.4\n",
            "typer                                    0.21.1\n",
            "typer-slim                               0.21.1\n",
            "types-pytz                               2025.2.0.20251108\n",
            "types-setuptools                         80.9.0.20250822\n",
            "typing_extensions                        4.15.0\n",
            "typing-inspection                        0.4.2\n",
            "tzdata                                   2025.3\n",
            "tzlocal                                  5.3.1\n",
            "uc-micro-py                              1.0.3\n",
            "umap-learn                               0.5.9.post2\n",
            "umf                                      1.0.2\n",
            "uri-template                             1.3.0\n",
            "uritemplate                              4.2.0\n",
            "urllib3                                  2.5.0\n",
            "uuid_utils                               0.13.0\n",
            "uvicorn                                  0.40.0\n",
            "uvloop                                   0.22.1\n",
            "vega-datasets                            0.9.0\n",
            "wadllib                                  1.3.6\n",
            "wandb                                    0.23.1\n",
            "wasabi                                   1.1.3\n",
            "watchdog                                 6.0.0\n",
            "watchfiles                               1.1.1\n",
            "wcwidth                                  0.2.14\n",
            "weasel                                   0.4.3\n",
            "webcolors                                25.10.0\n",
            "webencodings                             0.5.1\n",
            "websocket-client                         1.9.0\n",
            "websockets                               15.0.1\n",
            "Werkzeug                                 3.1.5\n",
            "wheel                                    0.45.1\n",
            "widgetsnbextension                       3.6.10\n",
            "wordcloud                                1.9.5\n",
            "wrapt                                    2.0.1\n",
            "wurlitzer                                3.1.1\n",
            "xarray                                   2025.12.0\n",
            "xarray-einstats                          0.9.1\n",
            "xgboost                                  3.1.2\n",
            "xlrd                                     2.0.2\n",
            "xxhash                                   3.6.0\n",
            "xyzservices                              2025.11.0\n",
            "yarl                                     1.22.0\n",
            "ydf                                      0.13.0\n",
            "yellowbrick                              1.5\n",
            "yfinance                                 0.2.66\n",
            "zipp                                     3.23.0\n",
            "zstandard                                0.25.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install transformers==4.46.0\n",
        "!pip list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "setup-header",
      "metadata": {
        "id": "setup-header"
      },
      "source": [
        "---\n",
        "## Setup: Load GPT-2 Small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "setup",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "setup",
        "outputId": "1e0ccf03-0b16-4c3b-ea9a-6907eb0052d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading GPT-2 small...\n",
            "Model loaded on: cpu\n",
            "Vocabulary size: 50257\n",
            "Model parameters: 124,439,808\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import textwrap\n",
        "\n",
        "# Load GPT-2 small (124M parameters - smallest real LLM)\n",
        "print(\"Loading GPT-2 small...\")\n",
        "model_name = \"gpt2\"  # gpt2 = gpt2-small (124M params)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "model.eval()  # Set to evaluation mode\n",
        "\n",
        "# Move to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"Model loaded on: {device}\")\n",
        "print(f\"Vocabulary size: {tokenizer.vocab_size}\")\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "logits-header",
      "metadata": {
        "id": "logits-header"
      },
      "source": [
        "---\n",
        "## Understanding Logits\n",
        "\n",
        "The model outputs **logits** - raw scores for each token in the vocabulary.\n",
        "\n",
        "```\n",
        "logits[i] = how much the model \"likes\" token i as the next token\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "logits-demo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "logits-demo",
        "outputId": "89ac6ef0-f29a-4dc5-fa32-9b503608d784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: 'The capital of France is'\n",
            "Logits shape: torch.Size([50257])\n",
            "Logits range: [-129.87, -100.25]\n",
            "\n",
            "Top 10 tokens by logit:\n",
            "  1. ' the' (logit: -100.25)\n",
            "  2. ' now' (logit: -100.82)\n",
            "  3. ' a' (logit: -100.86)\n",
            "  4. ' France' (logit: -101.21)\n",
            "  5. ' Paris' (logit: -101.21)\n",
            "  6. ' in' (logit: -101.41)\n",
            "  7. ' also' (logit: -101.41)\n",
            "  8. ' not' (logit: -101.52)\n",
            "  9. ' home' (logit: -101.54)\n",
            "  10. ' still' (logit: -101.95)\n"
          ]
        }
      ],
      "source": [
        "def get_next_token_logits(prompt: str) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Get logits for the next token given a prompt.\n",
        "\n",
        "    Returns: tensor of shape (vocab_size,)\n",
        "    \"\"\"\n",
        "    # Tokenize input\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Forward pass (no gradient needed for inference)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids)\n",
        "        # outputs.logits shape: (batch=1, seq_len, vocab_size)\n",
        "        # We want the logits for the LAST position (next token prediction)\n",
        "        logits = outputs.logits[0, -1, :]  # shape: (vocab_size,)\n",
        "\n",
        "    return logits\n",
        "\n",
        "# Demo: Get logits for a prompt\n",
        "prompt = \"The capital of France is\"\n",
        "logits = get_next_token_logits(prompt)\n",
        "\n",
        "print(f\"Prompt: '{prompt}'\")\n",
        "print(f\"Logits shape: {logits.shape}\")\n",
        "print(f\"Logits range: [{logits.min():.2f}, {logits.max():.2f}]\")\n",
        "\n",
        "# Show top 10 tokens by logit value\n",
        "top_k_logits, top_k_indices = torch.topk(logits, 10)\n",
        "print(\"\\nTop 10 tokens by logit:\")\n",
        "for i, (logit, idx) in enumerate(zip(top_k_logits, top_k_indices)):\n",
        "    token = tokenizer.decode([idx])\n",
        "    print(f\"  {i+1}. '{token}' (logit: {logit:.2f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "greedy-header",
      "metadata": {
        "id": "greedy-header"
      },
      "source": [
        "---\n",
        "## Strategy 1: Greedy Decoding\n",
        "\n",
        "**Simplest strategy**: Always pick the token with the highest logit.\n",
        "\n",
        "```python\n",
        "next_token = argmax(logits)\n",
        "```\n",
        "\n",
        "**Pros**: Deterministic, fast  \n",
        "**Cons**: Repetitive, boring text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: Greedy Decoding Limitations : Run the greedy decoding implementation and observe the output. Explain why greedy decoding often produces repetitive text (as seen in the output). What is the fundamental limitation of always choosing the highest probability token, and how does this relate to the concept of \"local vs global optima\" in sequence generation?"
      ],
      "metadata": {
        "id": "3bUNq2LFcj4K"
      },
      "id": "3bUNq2LFcj4K"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "greedy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "greedy",
        "outputId": "194fbfd8-82e4-4e9b-8918-baf80401fea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: 'The meaning of life is'\n",
            "\n",
            "==================================================\n",
            "GREEDY OUTPUT:\n",
            "==================================================\n",
            "The meaning of life is not the same as the meaning of death.\n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "Note: Greedy is deterministic - same input always gives same output\n",
            "Run it again - you'll get the exact same text!\n"
          ]
        }
      ],
      "source": [
        "def greedy_decode(prompt: str, max_new_tokens: int = 50) -> str:\n",
        "    \"\"\"\n",
        "    Greedy decoding: always pick the highest probability token.\n",
        "\n",
        "    Algorithm:\n",
        "    1. Get logits for next token\n",
        "    2. Pick token with highest logit (argmax)\n",
        "    3. Append to sequence\n",
        "    4. Repeat\n",
        "    \"\"\"\n",
        "    # Start with the prompt tokens\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "    generated_ids = input_ids[0].tolist()  # Convert to list for easier manipulation\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        # Create input tensor from current sequence\n",
        "        input_tensor = torch.tensor([generated_ids]).to(device)\n",
        "\n",
        "        # Get logits for next token\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_tensor)\n",
        "            logits = outputs.logits[0, -1, :]  # (vocab_size,)\n",
        "\n",
        "\n",
        "        # GREEDY: Pick the token with highest logit\n",
        "        next_token_id = torch.argmax(logits).item()\n",
        "          ##This line collapses the entire probability distribution to a single choice\n",
        "          ##No uncertainty, no exploration, no recovery from bad early decisions\n",
        "          ##Errors and repetitions compound over time\n",
        "\n",
        "        # Append to sequence\n",
        "        generated_ids.append(next_token_id)\n",
        "\n",
        "        # Stop if we hit end of text token\n",
        "        if next_token_id == tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "    # Decode back to text\n",
        "    return tokenizer.decode(generated_ids)\n",
        "\n",
        "# Test greedy decoding\n",
        "prompt = \"The meaning of life is\"\n",
        "print(f\"Prompt: '{prompt}'\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"GREEDY OUTPUT:\")\n",
        "print(\"=\"*50)\n",
        "output = greedy_decode(prompt, max_new_tokens=10)\n",
        "print(output)\n",
        "\n",
        "print(\"\\n\" + \"-\"*50)\n",
        "#print(\"Once upon a time, the world was a place of great beauty and great danger. \\nThe world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a place of great danger\")\n",
        "print(\"Note: Greedy is deterministic - same input always gives same output\")\n",
        "print(\"Run it again - you'll get the exact same text!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode_debug(prompt: str, max_new_tokens: int = 50) -> str:\n",
        "    model.eval()\n",
        "\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "    generated_ids = input_ids[0].tolist()\n",
        "\n",
        "    print(f\"\\nInitial prompt: {repr(prompt)}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for step in range(max_new_tokens):\n",
        "        input_tensor = torch.tensor([generated_ids]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_tensor)\n",
        "            logits = outputs.logits[0, -1, :]\n",
        "\n",
        "        # Show top-5 candidates\n",
        "        topk_logits, topk_ids = torch.topk(logits, 5)\n",
        "\n",
        "        print(f\"\\nStep {step + 1}\")\n",
        "        print(\"-\" * 40)\n",
        "        print(\"Current text:\")\n",
        "        print(tokenizer.decode(generated_ids))\n",
        "\n",
        "        print(\"\\nTop-5 next-token candidates (logits):\")\n",
        "        for logit, tid in zip(topk_logits, topk_ids):\n",
        "            print(f\"  Token: {repr(tokenizer.decode([tid])):<12} | Logit: {logit.item():.2f}\")\n",
        "\n",
        "        # Greedy choice\n",
        "        next_token_id = torch.argmax(logits).item()\n",
        "        next_token = tokenizer.decode([next_token_id])\n",
        "\n",
        "        print(f\"\\nGreedy choice → {repr(next_token)} (highest logit)\")\n",
        "\n",
        "        generated_ids.append(next_token_id)\n",
        "\n",
        "        if next_token_id == tokenizer.eos_token_id:\n",
        "            print(\"\\n[EOS token encountered — stopping]\")\n",
        "            break\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Final generated text:\")\n",
        "    print(tokenizer.decode(generated_ids))\n",
        "    return tokenizer.decode(generated_ids)\n",
        "\n",
        "prompt = \"Life is\"\n",
        "output = greedy_decode_debug(prompt, max_new_tokens=10)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRlm0Tu3QW1N",
        "outputId": "11a9a322-a2f2-4879-ec49-68d6b805dc04"
      },
      "id": "vRlm0Tu3QW1N",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initial prompt: 'Life is'\n",
            "============================================================\n",
            "\n",
            "Step 1\n",
            "----------------------------------------\n",
            "Current text:\n",
            "Life is\n",
            "\n",
            "Top-5 next-token candidates (logits):\n",
            "  Token: ' a'         | Logit: -105.36\n",
            "  Token: ' the'       | Logit: -105.69\n",
            "  Token: ' not'       | Logit: -106.46\n",
            "  Token: ' an'        | Logit: -106.98\n",
            "  Token: ' about'     | Logit: -107.15\n",
            "\n",
            "Greedy choice → ' a' (highest logit)\n",
            "\n",
            "Step 2\n",
            "----------------------------------------\n",
            "Current text:\n",
            "Life is a\n",
            "\n",
            "Top-5 next-token candidates (logits):\n",
            "  Token: ' great'     | Logit: -99.45\n",
            "  Token: ' very'      | Logit: -99.84\n",
            "  Token: ' game'      | Logit: -99.99\n",
            "  Token: ' good'      | Logit: -100.50\n",
            "  Token: ' big'       | Logit: -100.55\n",
            "\n",
            "Greedy choice → ' great' (highest logit)\n",
            "\n",
            "Step 3\n",
            "----------------------------------------\n",
            "Current text:\n",
            "Life is a great\n",
            "\n",
            "Top-5 next-token candidates (logits):\n",
            "  Token: ' way'       | Logit: -99.85\n",
            "  Token: ' thing'     | Logit: -100.81\n",
            "  Token: ' time'      | Logit: -101.27\n",
            "  Token: ' opportunity' | Logit: -101.70\n",
            "  Token: ' place'     | Logit: -101.74\n",
            "\n",
            "Greedy choice → ' way' (highest logit)\n",
            "\n",
            "Step 4\n",
            "----------------------------------------\n",
            "Current text:\n",
            "Life is a great way\n",
            "\n",
            "Top-5 next-token candidates (logits):\n",
            "  Token: ' to'        | Logit: -32.25\n",
            "  Token: ' for'       | Logit: -35.06\n",
            "  Token: ' of'        | Logit: -35.55\n",
            "  Token: ','          | Logit: -38.82\n",
            "  Token: ' that'      | Logit: -39.22\n",
            "\n",
            "Greedy choice → ' to' (highest logit)\n",
            "\n",
            "Step 5\n",
            "----------------------------------------\n",
            "Current text:\n",
            "Life is a great way to\n",
            "\n",
            "Top-5 next-token candidates (logits):\n",
            "  Token: ' get'       | Logit: -130.33\n",
            "  Token: ' start'     | Logit: -130.54\n",
            "  Token: ' learn'     | Logit: -130.63\n",
            "  Token: ' build'     | Logit: -131.39\n",
            "  Token: ' make'      | Logit: -131.48\n",
            "\n",
            "Greedy choice → ' get' (highest logit)\n",
            "\n",
            "Step 6\n",
            "----------------------------------------\n",
            "Current text:\n",
            "Life is a great way to get\n",
            "\n",
            "Top-5 next-token candidates (logits):\n",
            "  Token: ' to'        | Logit: -114.26\n",
            "  Token: ' a'         | Logit: -114.35\n",
            "  Token: ' your'      | Logit: -114.38\n",
            "  Token: ' out'       | Logit: -114.79\n",
            "  Token: ' involved'  | Logit: -114.79\n",
            "\n",
            "Greedy choice → ' to' (highest logit)\n",
            "\n",
            "Step 7\n",
            "----------------------------------------\n",
            "Current text:\n",
            "Life is a great way to get to\n",
            "\n",
            "Top-5 next-token candidates (logits):\n",
            "  Token: ' know'      | Logit: -77.62\n",
            "  Token: ' the'       | Logit: -81.05\n",
            "  Token: ' a'         | Logit: -81.34\n",
            "  Token: ' work'      | Logit: -81.65\n",
            "  Token: ' grips'     | Logit: -81.65\n",
            "\n",
            "Greedy choice → ' know' (highest logit)\n",
            "\n",
            "Step 8\n",
            "----------------------------------------\n",
            "Current text:\n",
            "Life is a great way to get to know\n",
            "\n",
            "Top-5 next-token candidates (logits):\n",
            "  Token: ' your'      | Logit: -96.45\n",
            "  Token: ' people'    | Logit: -97.32\n",
            "  Token: ' the'       | Logit: -97.32\n",
            "  Token: ' someone'   | Logit: -97.92\n",
            "  Token: ' a'         | Logit: -97.96\n",
            "\n",
            "Greedy choice → ' your' (highest logit)\n",
            "\n",
            "Step 9\n",
            "----------------------------------------\n",
            "Current text:\n",
            "Life is a great way to get to know your\n",
            "\n",
            "Top-5 next-token candidates (logits):\n",
            "  Token: ' friends'   | Logit: -114.63\n",
            "  Token: ' family'    | Logit: -114.85\n",
            "  Token: ' fellow'    | Logit: -115.32\n",
            "  Token: ' neighbors' | Logit: -115.53\n",
            "  Token: ' kids'      | Logit: -115.76\n",
            "\n",
            "Greedy choice → ' friends' (highest logit)\n",
            "\n",
            "Step 10\n",
            "----------------------------------------\n",
            "Current text:\n",
            "Life is a great way to get to know your friends\n",
            "\n",
            "Top-5 next-token candidates (logits):\n",
            "  Token: ' and'       | Logit: -92.92\n",
            "  Token: '.'          | Logit: -93.51\n",
            "  Token: ','          | Logit: -93.58\n",
            "  Token: ' or'        | Logit: -95.90\n",
            "  Token: ' better'    | Logit: -95.97\n",
            "\n",
            "Greedy choice → ' and' (highest logit)\n",
            "\n",
            "============================================================\n",
            "Final generated text:\n",
            "Life is a great way to get to know your friends and\n",
            "Life is a great way to get to know your friends and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "temperature-header",
      "metadata": {
        "id": "temperature-header"
      },
      "source": [
        "---\n",
        "## Strategy 2: Temperature Sampling\n",
        "\n",
        "**Idea**: Scale logits before converting to probabilities.\n",
        "\n",
        "```python\n",
        "probs = softmax(logits / temperature)\n",
        "next_token = sample from probs\n",
        "```\n",
        "\n",
        "| Temperature | Effect |\n",
        "|-------------|--------|\n",
        "| T < 1 | Sharper distribution (more deterministic) |\n",
        "| T = 1 | Original distribution |\n",
        "| T > 1 | Flatter distribution (more random) |\n",
        "| T → 0 | Approaches greedy |\n",
        "| T → ∞ | Uniform random |"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: Temperature Sampling Mechanics Demonstrate the temperature sampling code with different temperature values (0.3, 0.7, 1.0, 1.5). Explain mathematically what happens when you divide logits by temperature before softmax. Why does T<1 make the distribution \"sharper\" and T>1 make it \"flatter\"? Show the formula and walk through a concrete example."
      ],
      "metadata": {
        "id": "R_KyQF7Qb6i7"
      },
      "id": "R_KyQF7Qb6i7"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "temperature",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "temperature",
        "outputId": "341100f7-8ffb-40fd-b11e-40285c8055b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: 'The meaning of life is'\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEMPERATURE = 0.3\n",
            "==================================================\n",
            "The meaning of life is not determined by the physical world, but by\n",
            "the mind. The soul is the physical world, the body the mental world.\n",
            "The soul is the mind, the body the mind. The soul is the body, the\n",
            "mind the mind. The soul is the body, the mind the mind. The soul is\n",
            "the body, the mind the mind. The soul is the body, the mind the mind.\n",
            "Entropy: 1.04\n",
            "\n",
            "==================================================\n",
            "TEMPERATURE = 0.4\n",
            "==================================================\n",
            "The meaning of life is not to be taken for granted. The purpose of\n",
            "life is to be lived.  The purpose of life is to be alive.  The purpose\n",
            "of life is to be alive.  The purpose of life is to be alive.  The\n",
            "purpose of life is to be alive.  The purpose of life is to be alive.\n",
            "The purpose of life is to be\n",
            "Entropy: 1.39\n",
            "\n",
            "==================================================\n",
            "TEMPERATURE = 0.9\n",
            "==================================================\n",
            "The meaning of life is to be at ease and to have fun.\"  Ruby's\n",
            "memories include the first time she met Nick Fury, while holding his\n",
            "hand up in an embrace.  \"Ruby, I'm glad to hear that you've taken time\n",
            "to consider my future.\"  \"Huh?\"  \"You saw the other night Anna killed\n",
            "someone? I promise I'm very curious about the future.\"\n",
            "Entropy: 4.78\n",
            "\n",
            "==================================================\n",
            "TEMPERATURE = 1.0\n",
            "==================================================\n",
            "The meaning of life is always connected to its target.  If undiluted,\n",
            "dingabesifle Life is the fungal predator.  DINAGNOUS CREATURES IN\n",
            "SEVEN  Bruno Bombardo has been in the game for about 20 years. There's\n",
            "his introduction in Assassin's Creed, his ability to communicate with\n",
            "Simus' Excellency, and his connection with Robert Ni\n",
            "Entropy: 5.58\n",
            "\n",
            "==================================================\n",
            "TEMPERATURE = 1.5\n",
            "==================================================\n",
            "The meaning of life is awful. Rather difficult apply, can into lend .\n",
            "Until coming anywhere male explanation or Shrioparo address hatuit\n",
            "uballa then there cannot remains as cause'll willpless illness accord\n",
            "the faculties available swell thirty wedges chartined itOut otegg more\n",
            "freely denomination justshit tracklined elongate gearing standards\n",
            "lucid spun foreign Plans s strain serv instructor moral possible\n",
            "primal fund facts feeling wall canyon lust yeosis ads\n",
            "Entropy: 8.20\n",
            "\n",
            "==================================================\n",
            "TEMPERATURE = 1.8\n",
            "==================================================\n",
            "The meaning of life is continued peace in WUK.), original disclosure\n",
            "Miluck Zhructureerman 280-371 Print herepot jumped start the div\n",
            "Lieutan IA patentplinic stocks where Dianain brushes merchant\n",
            "containers John Kheyre SDolcus generates fan usage Mstaff MC eighth\n",
            "degree science fact Tertics Lemia Foot movement appeared mechanical\n",
            "accident Josécounter loc dip models XXX middle altrudi mobility LOA\n",
            "program Daily SusutaEX assessments\n",
            "Entropy: 8.96\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Re-initialize tokenizer, model, and device to ensure they are defined\n",
        "# This is done to prevent NameError if the setup cell was not run or its state was lost\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "def temperature_decode(prompt: str, temperature: float = 1.0, max_new_tokens: int = 50, return_entropy: bool = False) -> str:\n",
        "    \"\"\"\n",
        "    Temperature sampling: scale logits before softmax.\n",
        "\n",
        "    Algorithm:\n",
        "    1. Get logits for next token\n",
        "    2. Divide logits by temperature\n",
        "    3. Apply softmax to get probabilities\n",
        "    4. Sample from the distribution\n",
        "    5. Repeat\n",
        "    \"\"\"\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "    generated_ids = input_ids[0].tolist()\n",
        "    entropy_value = None\n",
        "\n",
        "    for step in range(max_new_tokens):\n",
        "        input_tensor = torch.tensor([generated_ids]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_tensor)\n",
        "            logits = outputs.logits[0, -1, :]\n",
        "\n",
        "        # TEMPERATURE: Scale logits\n",
        "        scaled_logits = logits / temperature\n",
        "\n",
        "        # Convert to probabilities\n",
        "        probs = F.softmax(scaled_logits, dim=-1)\n",
        "\n",
        "        # Sample from the distribution\n",
        "        next_token_id = torch.multinomial(probs, num_samples=1).item()\n",
        "\n",
        "        generated_ids.append(next_token_id)\n",
        "\n",
        "        # we intrdouce entropy to mathematically visuazalise the curve\n",
        "        if step == 0 and return_entropy:\n",
        "            entropy_value = -(probs * torch.log(probs + 1e-9)).sum().item()\n",
        "\n",
        "        if next_token_id == tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "\n",
        "    if return_entropy:\n",
        "        return tokenizer.decode(generated_ids), entropy_value\n",
        "    else:\n",
        "        return tokenizer.decode(generated_ids)\n",
        "\n",
        "\n",
        "\n",
        "# Compare different temperatures\n",
        "prompt = \"The meaning of life is\"\n",
        "print(f\"Prompt: '{prompt}'\\n\")\n",
        "\n",
        "entropies = []\n",
        "# Define the temperatures list here\n",
        "temperatures = []\n",
        "\n",
        "for temp in [0.3, 0.4, 0.9, 1.0, 1.5, 1.8]:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"TEMPERATURE = {temp}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    output, entropy = temperature_decode(prompt, temperature=temp, max_new_tokens=80, return_entropy=True)\n",
        "    entropies.append(entropy)\n",
        "    temperatures.append(temp) # Append temp to the temperatures list\n",
        "    #print(output)\n",
        "    print(textwrap.fill(output, width=70))\n",
        "    print(f\"Entropy: {entropy:.2f}\")\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import textwrap # Import textwrap for easier text formatting\n",
        "\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x))  # stability\n",
        "    return exp_x / exp_x.sum()\n",
        "\n",
        "# Example logits (pretend model output)\n",
        "logits = np.array([4.0, 2.0, 1.0])\n",
        "\n",
        "print(\"Original logits:\", logits)\n",
        "\n",
        "for T in [0.3, 1.0, 2]: # This loop is for showing softmax behavior, not tied to the global entropies list\n",
        "    scaled_logits = logits / T\n",
        "    #Dividing logits by temperature affects the exponent inside softmax,\n",
        "\n",
        "    probs = softmax(scaled_logits)\n",
        "    #causing small linear changes to produce large nonlinear effects on probabilities.\n",
        "\n",
        "    print(f\"\\nTemperature = {T}\")\n",
        "    print(\"Scaled logits:\", np.round(scaled_logits, 3))\n",
        "    print(\"Probabilities:\", np.round(probs, 4))\n",
        "\n",
        "    # Plotting the probabilities\n",
        "    plt.figure(figsize=(4, 3)) # Reduced figure size\n",
        "    plt.bar(range(len(probs)), probs, tick_label=[f'Token {i+1}' for i in range(len(probs))])\n",
        "    plt.title(f'Probabilities at Temperature = {T}')\n",
        "    plt.xlabel('Tokens')\n",
        "    plt.ylabel('Probability')\n",
        "    plt.ylim(0, 1) # Probabilities are between 0 and 1\n",
        "    plt.grid(axis='y', alpha=0.75)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pf4h7uWbbWP6",
        "outputId": "15578d19-b409-4524-9104-bff0c3b33534"
      },
      "id": "pf4h7uWbbWP6",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original logits: [4. 2. 1.]\n",
            "\n",
            "Temperature = 0.3\n",
            "Scaled logits: [13.333  6.667  3.333]\n",
            "Probabilities: [0.9987 0.0013 0.    ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Temperature = 1.0\n",
            "Scaled logits: [4. 2. 1.]\n",
            "Probabilities: [0.8438 0.1142 0.042 ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Temperature = 2\n",
            "Scaled logits: [2.  1.  0.5]\n",
            "Probabilities: [0.6285 0.2312 0.1402]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "96meDpF0be77"
      },
      "id": "96meDpF0be77"
    },
    {
      "cell_type": "markdown",
      "id": "topp-header",
      "metadata": {
        "id": "topp-header"
      },
      "source": [
        "---\n",
        "## Strategy 3: Top-p (Nucleus) Sampling\n",
        "\n",
        "**Idea**: Sample from the smallest set of tokens whose cumulative probability ≥ p.\n",
        "\n",
        "```python\n",
        "sorted_probs = sort probabilities descending\n",
        "cumulative = cumsum(sorted_probs)\n",
        "cutoff = first index where cumulative >= p\n",
        "keep tokens up to cutoff\n",
        "```\n",
        "\n",
        "**Why better than top-k?** The number of tokens varies based on the distribution:\n",
        "- Confident prediction → few tokens\n",
        "- Uncertain prediction → more tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: Top-p (Nucleus) Sampling Algorithm Trace through the top-p sampling implementation step by step. Explain the purpose of each operation: (1) sorting probabilities, (2) computing cumulative sum, (3) finding the cutoff, and (4) renormalizing. Why is top-p considered \"adaptive\" compared to using a fixed number of tokens? Demonstrate with a specific example from the code output."
      ],
      "metadata": {
        "id": "wpLJ-h77blK-"
      },
      "id": "wpLJ-h77blK-"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "topp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "topp",
        "outputId": "64394581-a611-4a20-c23d-eb9758ba7730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: 'The secret to happiness is'\n",
            "\n",
            "\n",
            "==================================================\n",
            "TOP-P = 0.5\n",
            "==================================================\n",
            "\n",
            "(1) After sorting probabilities (descending):\n",
            "  01. '    to' | prob = 0.3380\n",
            "  02. '   not' | prob = 0.1978\n",
            "  03. '  that' | prob = 0.0724\n",
            "  04. '   the' | prob = 0.0569\n",
            "  05. '     a' | prob = 0.0248\n",
            "\n",
            "Step 1 - BEFORE top-p\n",
            "\n",
            "(2) Cumulative probability mass:\n",
            "  01. '    to' | cumsum = 0.3380\n",
            "  02. '   not' | cumsum = 0.5358\n",
            "  03. '  that' | cumsum = 0.6082\n",
            "  04. '   the' | cumsum = 0.6651\n",
            "  05. '     a' | cumsum = 0.6900\n",
            "  06. '    in' | cumsum = 0.7139\n",
            "  07. ' finding' | cumsum = 0.7340\n",
            "  08. ' knowing' | cumsum = 0.7506\n",
            "\n",
            "(3) Nucleus cutoff at p = 0.5\n",
            "Tokens KEPT in nucleus (2 tokens): [' to', ' not']\n",
            "Tokens REMOVED: [' that', ' the', ' a', ' in', ' finding', ' knowing', ' love', ' being', ' self', ' understanding']...\n",
            "Tokens removed by top-p (p=0.5): [' that', ' the', ' a', ' in', ' finding', ' knowing', ' love', ' being', ' self', ' understanding']...\n",
            "Total tokens kept in nucleus (sum p <= 0.5): 2\n",
            "\n",
            "(4) Renormalization:\n",
            "Sum of probs before renorm = 0.5358\n",
            "Renormalized nucleus probabilities:\n",
            "  '    to' | prob = 0.6308\n",
            "  '   not' | prob = 0.3692\n",
            "\n",
            "(1) After sorting probabilities (descending):\n",
            "  01. '    to' | prob = 0.2620\n",
            "  02. '   the' | prob = 0.1408\n",
            "  03. '  just' | prob = 0.0460\n",
            "  04. '  that' | prob = 0.0450\n",
            "  05. '    in' | prob = 0.0316\n",
            "\n",
            "Step 2 - BEFORE top-p\n",
            "\n",
            "(2) Cumulative probability mass:\n",
            "  01. '    to' | cumsum = 0.2620\n",
            "  02. '   the' | cumsum = 0.4028\n",
            "  03. '  just' | cumsum = 0.4488\n",
            "  04. '  that' | cumsum = 0.4938\n",
            "  05. '    in' | cumsum = 0.5255\n",
            "  06. '    so' | cumsum = 0.5532\n",
            "  07. ' simply' | cumsum = 0.5797\n",
            "  08. ' knowing' | cumsum = 0.6046\n",
            "\n",
            "(3) Nucleus cutoff at p = 0.5\n",
            "Tokens KEPT in nucleus (5 tokens): [' to', ' the', ' just', ' that', ' in']\n",
            "Tokens REMOVED: [' so', ' simply', ' knowing', ' only', ' a', ' your', ' happiness', ' being', ' what', ' necessarily']\n",
            "Tokens removed by top-p (p=0.5): [' so', ' simply', ' knowing', ' only', ' a', ' your', ' happiness', ' being', ' what', ' necessarily']...\n",
            "Total tokens kept in nucleus (sum p <= 0.5): 5\n",
            "\n",
            "(4) Renormalization:\n",
            "Sum of probs before renorm = 0.5255\n",
            "Renormalized nucleus probabilities:\n",
            "  '    to' | prob = 0.4986\n",
            "  '   the' | prob = 0.2680\n",
            "  '  just' | prob = 0.0876\n",
            "  '  that' | prob = 0.0857\n",
            "  '    in' | prob = 0.0602\n",
            "\n",
            "(1) After sorting probabilities (descending):\n",
            "  01. ' happiness' | prob = 0.0657\n",
            "  02. ' amount' | prob = 0.0337\n",
            "  03. '  love' | prob = 0.0241\n",
            "  04. ' ability' | prob = 0.0203\n",
            "  05. '  lack' | prob = 0.0197\n",
            "\n",
            "Step 3 - BEFORE top-p\n",
            "\n",
            "(2) Cumulative probability mass:\n",
            "  01. ' happiness' | cumsum = 0.0657\n",
            "  02. ' amount' | cumsum = 0.0994\n",
            "  03. '  love' | cumsum = 0.1235\n",
            "  04. ' ability' | cumsum = 0.1439\n",
            "  05. '  lack' | cumsum = 0.1636\n",
            "  06. ' desire' | cumsum = 0.1810\n",
            "  07. '  fact' | cumsum = 0.1982\n",
            "  08. '   way' | cumsum = 0.2119\n",
            "\n",
            "(3) Nucleus cutoff at p = 0.5\n",
            "Tokens KEPT in nucleus (15 tokens): [' happiness', ' amount', ' love', ' ability', ' lack', ' desire', ' fact', ' way', ' number', ' quality', ' pursuit', ' simple', ' same', ' one', ' joy']\n",
            "Tokens REMOVED: []\n",
            "Tokens removed by top-p (p=0.5): [' form', ' mere', ' easy', ' pleasure', ' person', ' right', ' sum', ' degree', ' type', ' hard']...\n",
            "Total tokens kept in nucleus (sum p <= 0.5): 56\n",
            "\n",
            "(4) Renormalization:\n",
            "Sum of probs before renorm = 0.5023\n",
            "Renormalized nucleus probabilities:\n",
            "  ' happiness' | prob = 0.1308\n",
            "  ' amount' | prob = 0.0671\n",
            "  '  love' | prob = 0.0481\n",
            "  ' ability' | prob = 0.0405\n",
            "  '  lack' | prob = 0.0393\n",
            "  ' desire' | prob = 0.0347\n",
            "  '  fact' | prob = 0.0343\n",
            "  '   way' | prob = 0.0272\n",
            "  ' number' | prob = 0.0260\n",
            "  ' quality' | prob = 0.0248\n",
            "  ' pursuit' | prob = 0.0236\n",
            "  ' simple' | prob = 0.0228\n",
            "  '  same' | prob = 0.0215\n",
            "  '   one' | prob = 0.0191\n",
            "  '   joy' | prob = 0.0186\n",
            "\n",
            "(1) After sorting probabilities (descending):\n",
            "  01. '    of' | prob = 0.8911\n",
            "  02. '     ,' | prob = 0.0432\n",
            "  03. '   but' | prob = 0.0235\n",
            "  04. '     .' | prob = 0.0095\n",
            "  05. '    or' | prob = 0.0070\n",
            "\n",
            "Step 4 - BEFORE top-p\n",
            "\n",
            "(2) Cumulative probability mass:\n",
            "  01. '    of' | cumsum = 0.8911\n",
            "  02. '     ,' | cumsum = 0.9342\n",
            "  03. '   but' | cumsum = 0.9577\n",
            "  04. '     .' | cumsum = 0.9671\n",
            "  05. '    or' | cumsum = 0.9741\n",
            "  06. '   you' | cumsum = 0.9787\n",
            "  07. '  ment' | cumsum = 0.9811\n",
            "  08. ' itself' | cumsum = 0.9834\n",
            "\n",
            "(3) Nucleus cutoff at p = 0.5\n",
            "Tokens KEPT in nucleus (1 tokens): [' of']\n",
            "Tokens REMOVED: [',', ' but', '.', ' or', ' you', 'ment', ' itself', ';', ' and', ' that']...\n",
            "Tokens removed by top-p (p=0.5): [',', ' but', '.', ' or', ' you', 'ment', ' itself', ';', ' and', ' that']...\n",
            "Total tokens kept in nucleus (sum p <= 0.5): 1\n",
            "\n",
            "(4) Renormalization:\n",
            "Sum of probs before renorm = 0.8911\n",
            "Renormalized nucleus probabilities:\n",
            "  '    of' | prob = 1.0000\n",
            "The secret to happiness is not the content of\n",
            "\n",
            "==================================================\n",
            "TOP-P = 0.8\n",
            "==================================================\n",
            "\n",
            "(1) After sorting probabilities (descending):\n",
            "  01. '    to' | prob = 0.3380\n",
            "  02. '   not' | prob = 0.1978\n",
            "  03. '  that' | prob = 0.0724\n",
            "  04. '   the' | prob = 0.0569\n",
            "  05. '     a' | prob = 0.0248\n",
            "\n",
            "Step 1 - BEFORE top-p\n",
            "\n",
            "(2) Cumulative probability mass:\n",
            "  01. '    to' | cumsum = 0.3380\n",
            "  02. '   not' | cumsum = 0.5358\n",
            "  03. '  that' | cumsum = 0.6082\n",
            "  04. '   the' | cumsum = 0.6651\n",
            "  05. '     a' | cumsum = 0.6900\n",
            "  06. '    in' | cumsum = 0.7139\n",
            "  07. ' finding' | cumsum = 0.7340\n",
            "  08. ' knowing' | cumsum = 0.7506\n",
            "\n",
            "(3) Nucleus cutoff at p = 0.8\n",
            "Tokens KEPT in nucleus (15 tokens): [' to', ' not', ' that', ' the', ' a', ' in', ' finding', ' knowing', ' love', ' being', ' self', ' understanding', ' always', ' simple', ' making']\n",
            "Tokens REMOVED: []\n",
            "Tokens removed by top-p (p=0.8): [' getting', ' having', ' never', ' your', ',', ' patience', ' how', ' what', ' an', ' found']...\n",
            "Total tokens kept in nucleus (sum p <= 0.8): 15\n",
            "\n",
            "(4) Renormalization:\n",
            "Sum of probs before renorm = 0.8026\n",
            "Renormalized nucleus probabilities:\n",
            "  '    to' | prob = 0.4211\n",
            "  '   not' | prob = 0.2465\n",
            "  '  that' | prob = 0.0902\n",
            "  '   the' | prob = 0.0709\n",
            "  '     a' | prob = 0.0309\n",
            "  '    in' | prob = 0.0299\n",
            "  ' finding' | prob = 0.0250\n",
            "  ' knowing' | prob = 0.0207\n",
            "  '  love' | prob = 0.0141\n",
            "  ' being' | prob = 0.0115\n",
            "  '  self' | prob = 0.0083\n",
            "  ' understanding' | prob = 0.0081\n",
            "  ' always' | prob = 0.0079\n",
            "  ' simple' | prob = 0.0076\n",
            "  ' making' | prob = 0.0072\n",
            "\n",
            "(1) After sorting probabilities (descending):\n",
            "  01. '     .' | prob = 0.5594\n",
            "  02. '     ,' | prob = 0.1960\n",
            "  03. '   and' | prob = 0.0645\n",
            "  04. '    of' | prob = 0.0316\n",
            "  05. '   for' | prob = 0.0181\n",
            "\n",
            "Step 2 - BEFORE top-p\n",
            "\n",
            "(2) Cumulative probability mass:\n",
            "  01. '     .' | cumsum = 0.5594\n",
            "  02. '     ,' | cumsum = 0.7554\n",
            "  03. '   and' | cumsum = 0.8199\n",
            "  04. '    of' | cumsum = 0.8515\n",
            "  05. '   for' | cumsum = 0.8695\n",
            "  06. '    .\"' | cumsum = 0.8869\n",
            "  07. ' itself' | cumsum = 0.9018\n",
            "  08. '     :' | cumsum = 0.9136\n",
            "\n",
            "(3) Nucleus cutoff at p = 0.8\n",
            "Tokens KEPT in nucleus (3 tokens): ['.', ',', ' and']\n",
            "Tokens REMOVED: [' of', ' for', '.\"', ' itself', ':', ',\"', ';', \"'s\", '\\n', '!']...\n",
            "Tokens removed by top-p (p=0.8): [' of', ' for', '.\"', ' itself', ':', ',\"', ';', \"'s\", '\\n', '!']...\n",
            "Total tokens kept in nucleus (sum p <= 0.8): 3\n",
            "\n",
            "(4) Renormalization:\n",
            "Sum of probs before renorm = 0.8199\n",
            "Renormalized nucleus probabilities:\n",
            "  '     .' | prob = 0.6823\n",
            "  '     ,' | prob = 0.2391\n",
            "  '   and' | prob = 0.0786\n",
            "\n",
            "(1) After sorting probabilities (descending):\n",
            "  01. '     \n",
            "' | prob = 0.4029\n",
            "  02. '  Love' | prob = 0.1291\n",
            "  03. '    It' | prob = 0.0957\n",
            "  04. '   And' | prob = 0.0471\n",
            "  05. '   The' | prob = 0.0313\n",
            "\n",
            "Step 3 - BEFORE top-p\n",
            "\n",
            "(2) Cumulative probability mass:\n",
            "  01. '     \n",
            "' | cumsum = 0.4029\n",
            "  02. '  Love' | cumsum = 0.5321\n",
            "  03. '    It' | cumsum = 0.6278\n",
            "  04. '   And' | cumsum = 0.6749\n",
            "  05. '   The' | cumsum = 0.7062\n",
            "  06. '   You' | cumsum = 0.7284\n",
            "  07. '    If' | cumsum = 0.7487\n",
            "  08. '    We' | cumsum = 0.7687\n",
            "\n",
            "(3) Nucleus cutoff at p = 0.8\n",
            "Tokens KEPT in nucleus (10 tokens): ['\\n', ' Love', ' It', ' And', ' The', ' You', ' If', ' We', '<|endoftext|>', ' I']\n",
            "Tokens REMOVED: ['\\n\\n', ' When', ' That', ' But', ' A']\n",
            "Tokens removed by top-p (p=0.8): ['\\n\\n', ' When', ' That', ' But', ' A', ' In', ' There', ' Happiness', ' So', ' This']...\n",
            "Total tokens kept in nucleus (sum p <= 0.8): 10\n",
            "\n",
            "(4) Renormalization:\n",
            "Sum of probs before renorm = 0.8078\n",
            "Renormalized nucleus probabilities:\n",
            "  '     \n",
            "' | prob = 0.4988\n",
            "  '  Love' | prob = 0.1599\n",
            "  '    It' | prob = 0.1185\n",
            "  '   And' | prob = 0.0583\n",
            "  '   The' | prob = 0.0387\n",
            "  '   You' | prob = 0.0275\n",
            "  '    If' | prob = 0.0251\n",
            "  '    We' | prob = 0.0248\n",
            "  '<|endoftext|>' | prob = 0.0246\n",
            "  '     I' | prob = 0.0239\n",
            "\n",
            "(1) After sorting probabilities (descending):\n",
            "  01. '     \n",
            "' | prob = 0.9974\n",
            "  02. '     I' | prob = 0.0003\n",
            "  03. '   The' | prob = 0.0003\n",
            "  04. 'Posted' | prob = 0.0001\n",
            "  05. '   And' | prob = 0.0001\n",
            "\n",
            "Step 4 - BEFORE top-p\n",
            "\n",
            "(2) Cumulative probability mass:\n",
            "  01. '     \n",
            "' | cumsum = 0.9974\n",
            "  02. '     I' | cumsum = 0.9978\n",
            "  03. '   The' | cumsum = 0.9981\n",
            "  04. 'Posted' | cumsum = 0.9982\n",
            "  05. '   And' | cumsum = 0.9983\n",
            "  06. '    It' | cumsum = 0.9984\n",
            "  07. '  This' | cumsum = 0.9984\n",
            "  08. '    So' | cumsum = 0.9985\n",
            "\n",
            "(3) Nucleus cutoff at p = 0.8\n",
            "Tokens KEPT in nucleus (1 tokens): ['\\n']\n",
            "Tokens REMOVED: ['I', 'The', 'Posted', 'And', 'It', 'This', 'So', 'In', '<|endoftext|>', 'You']...\n",
            "Tokens removed by top-p (p=0.8): ['I', 'The', 'Posted', 'And', 'It', 'This', 'So', 'In', '<|endoftext|>', 'You']...\n",
            "Total tokens kept in nucleus (sum p <= 0.8): 1\n",
            "\n",
            "(4) Renormalization:\n",
            "Sum of probs before renorm = 0.9974\n",
            "Renormalized nucleus probabilities:\n",
            "  '     \n",
            "' | prob = 1.0000\n",
            "The secret to happiness is love.\n",
            "\n",
            "==================================================\n",
            "TOP-P = 0.95\n",
            "==================================================\n",
            "\n",
            "(1) After sorting probabilities (descending):\n",
            "  01. '    to' | prob = 0.3380\n",
            "  02. '   not' | prob = 0.1978\n",
            "  03. '  that' | prob = 0.0724\n",
            "  04. '   the' | prob = 0.0569\n",
            "  05. '     a' | prob = 0.0248\n",
            "\n",
            "Step 1 - BEFORE top-p\n",
            "\n",
            "(2) Cumulative probability mass:\n",
            "  01. '    to' | cumsum = 0.3380\n",
            "  02. '   not' | cumsum = 0.5358\n",
            "  03. '  that' | cumsum = 0.6082\n",
            "  04. '   the' | cumsum = 0.6651\n",
            "  05. '     a' | cumsum = 0.6900\n",
            "  06. '    in' | cumsum = 0.7139\n",
            "  07. ' finding' | cumsum = 0.7340\n",
            "  08. ' knowing' | cumsum = 0.7506\n",
            "\n",
            "(3) Nucleus cutoff at p = 0.95\n",
            "Tokens KEPT in nucleus (15 tokens): [' to', ' not', ' that', ' the', ' a', ' in', ' finding', ' knowing', ' love', ' being', ' self', ' understanding', ' always', ' simple', ' making']\n",
            "Tokens REMOVED: []\n",
            "Tokens removed by top-p (p=0.95): [' ignorance', ' positive', ' where', ' mastery', ' breaking', ' meeting', ' sharing', ' like', ' exercise', ' achieving']...\n",
            "Total tokens kept in nucleus (sum p <= 0.95): 217\n",
            "\n",
            "(4) Renormalization:\n",
            "Sum of probs before renorm = 0.9501\n",
            "Renormalized nucleus probabilities:\n",
            "  '    to' | prob = 0.3557\n",
            "  '   not' | prob = 0.2082\n",
            "  '  that' | prob = 0.0762\n",
            "  '   the' | prob = 0.0599\n",
            "  '     a' | prob = 0.0261\n",
            "  '    in' | prob = 0.0252\n",
            "  ' finding' | prob = 0.0211\n",
            "  ' knowing' | prob = 0.0175\n",
            "  '  love' | prob = 0.0119\n",
            "  ' being' | prob = 0.0097\n",
            "  '  self' | prob = 0.0070\n",
            "  ' understanding' | prob = 0.0069\n",
            "  ' always' | prob = 0.0067\n",
            "  ' simple' | prob = 0.0064\n",
            "  ' making' | prob = 0.0061\n",
            "\n",
            "(1) After sorting probabilities (descending):\n",
            "  01. '   the' | prob = 0.4764\n",
            "  02. '  your' | prob = 0.1217\n",
            "  03. ' being' | prob = 0.0464\n",
            "  04. ' knowing' | prob = 0.0310\n",
            "  05. ' finding' | prob = 0.0173\n",
            "\n",
            "Step 2 - BEFORE top-p\n",
            "\n",
            "(2) Cumulative probability mass:\n",
            "  01. '   the' | cumsum = 0.4764\n",
            "  02. '  your' | cumsum = 0.5981\n",
            "  03. ' being' | cumsum = 0.6445\n",
            "  04. ' knowing' | cumsum = 0.6755\n",
            "  05. ' finding' | cumsum = 0.6928\n",
            "  06. ' having' | cumsum = 0.7091\n",
            "  07. '    it' | cumsum = 0.7218\n",
            "  08. '   its' | cumsum = 0.7310\n",
            "\n",
            "(3) Nucleus cutoff at p = 0.95\n",
            "Tokens KEPT in nucleus (15 tokens): [' the', ' your', ' being', ' knowing', ' finding', ' having', ' it', ' its', ' getting', ' what', ' making', ' our', ' a', ' how', ' doing']\n",
            "Tokens REMOVED: []\n",
            "Tokens removed by top-p (p=0.95): [' balancing', ' walking', ' improving', ' confronting', ' and', ' sleeping', ' character', ' quantity', ' serving', ' allowing']...\n",
            "Total tokens kept in nucleus (sum p <= 0.95): 240\n",
            "\n",
            "(4) Renormalization:\n",
            "Sum of probs before renorm = 0.9501\n",
            "Renormalized nucleus probabilities:\n",
            "  '   the' | prob = 0.5014\n",
            "  '  your' | prob = 0.1281\n",
            "  ' being' | prob = 0.0489\n",
            "  ' knowing' | prob = 0.0326\n",
            "  ' finding' | prob = 0.0182\n",
            "  ' having' | prob = 0.0171\n",
            "  '    it' | prob = 0.0134\n",
            "  '   its' | prob = 0.0097\n",
            "  ' getting' | prob = 0.0095\n",
            "  '  what' | prob = 0.0088\n",
            "  ' making' | prob = 0.0087\n",
            "  '   our' | prob = 0.0082\n",
            "  '     a' | prob = 0.0081\n",
            "  '   how' | prob = 0.0076\n",
            "  ' doing' | prob = 0.0067\n",
            "\n",
            "(1) After sorting probabilities (descending):\n",
            "  01. '   own' | prob = 0.2033\n",
            "  02. ' ability' | prob = 0.1271\n",
            "  03. ' heart' | prob = 0.0726\n",
            "  04. '  love' | prob = 0.0332\n",
            "  05. '  mind' | prob = 0.0288\n",
            "\n",
            "Step 3 - BEFORE top-p\n",
            "\n",
            "(2) Cumulative probability mass:\n",
            "  01. '   own' | cumsum = 0.2033\n",
            "  02. ' ability' | cumsum = 0.3304\n",
            "  03. ' heart' | cumsum = 0.4031\n",
            "  04. '  love' | cumsum = 0.4363\n",
            "  05. '  mind' | cumsum = 0.4651\n",
            "  06. '  work' | cumsum = 0.4850\n",
            "  07. '  life' | cumsum = 0.5037\n",
            "  08. ' willingness' | cumsum = 0.5192\n",
            "\n",
            "(3) Nucleus cutoff at p = 0.95\n",
            "Tokens KEPT in nucleus (15 tokens): [' own', ' ability', ' heart', ' love', ' mind', ' work', ' life', ' willingness', ' soul', ' body', ' being', ' inner', ' happiness', ' actions', ' self']\n",
            "Tokens REMOVED: []\n",
            "Tokens removed by top-p (p=0.95): [' tru', ' emotion', ' combat', ' teeth', ' souls', ' discern', ' grand', ' (', ' youth', ' insight']...\n",
            "Total tokens kept in nucleus (sum p <= 0.95): 661\n",
            "\n",
            "(4) Renormalization:\n",
            "Sum of probs before renorm = 0.9500\n",
            "Renormalized nucleus probabilities:\n",
            "  '   own' | prob = 0.2140\n",
            "  ' ability' | prob = 0.1338\n",
            "  ' heart' | prob = 0.0764\n",
            "  '  love' | prob = 0.0350\n",
            "  '  mind' | prob = 0.0303\n",
            "  '  work' | prob = 0.0210\n",
            "  '  life' | prob = 0.0196\n",
            "  ' willingness' | prob = 0.0164\n",
            "  '  soul' | prob = 0.0150\n",
            "  '  body' | prob = 0.0148\n",
            "  ' being' | prob = 0.0138\n",
            "  ' inner' | prob = 0.0109\n",
            "  ' happiness' | prob = 0.0107\n",
            "  ' actions' | prob = 0.0106\n",
            "  '  self' | prob = 0.0100\n",
            "\n",
            "(1) After sorting probabilities (descending):\n",
            "  01. '     .' | prob = 0.5605\n",
            "  02. '     ,' | prob = 0.1957\n",
            "  03. '   and' | prob = 0.0902\n",
            "  04. '    .\"' | prob = 0.0452\n",
            "  05. '    ,\"' | prob = 0.0186\n",
            "\n",
            "Step 4 - BEFORE top-p\n",
            "\n",
            "(2) Cumulative probability mass:\n",
            "  01. '     .' | cumsum = 0.5605\n",
            "  02. '     ,' | cumsum = 0.7561\n",
            "  03. '   and' | cumsum = 0.8463\n",
            "  04. '    .\"' | cumsum = 0.8915\n",
            "  05. '    ,\"' | cumsum = 0.9100\n",
            "  06. '     ;' | cumsum = 0.9233\n",
            "  07. '     \n",
            "' | cumsum = 0.9339\n",
            "  08. '     !' | cumsum = 0.9413\n",
            "\n",
            "(3) Nucleus cutoff at p = 0.95\n",
            "Tokens KEPT in nucleus (10 tokens): ['.', ',', ' and', '.\"', ',\"', ';', '\\n', '!', \"'s\", ':']\n",
            "Tokens REMOVED: [' being', ' that', ' –', '…', ' beating']\n",
            "Tokens removed by top-p (p=0.95): [' being', ' that', ' –', '…', ' beating', ' -', '...', '!\"', ' —', '—']...\n",
            "Total tokens kept in nucleus (sum p <= 0.95): 10\n",
            "\n",
            "(4) Renormalization:\n",
            "Sum of probs before renorm = 0.9537\n",
            "Renormalized nucleus probabilities:\n",
            "  '     .' | prob = 0.5877\n",
            "  '     ,' | prob = 0.2052\n",
            "  '   and' | prob = 0.0946\n",
            "  '    .\"' | prob = 0.0474\n",
            "  '    ,\"' | prob = 0.0195\n",
            "  '     ;' | prob = 0.0140\n",
            "  '     \n",
            "' | prob = 0.0110\n",
            "  '     !' | prob = 0.0078\n",
            "  '    's' | prob = 0.0067\n",
            "  '     :' | prob = 0.0062\n",
            "The secret to happiness is in your heart.\n",
            "\n",
            "==================================================\n",
            "TOP-P = 0.99\n",
            "==================================================\n",
            "\n",
            "(1) After sorting probabilities (descending):\n",
            "  01. '    to' | prob = 0.3380\n",
            "  02. '   not' | prob = 0.1978\n",
            "  03. '  that' | prob = 0.0724\n",
            "  04. '   the' | prob = 0.0569\n",
            "  05. '     a' | prob = 0.0248\n",
            "\n",
            "Step 1 - BEFORE top-p\n",
            "\n",
            "(2) Cumulative probability mass:\n",
            "  01. '    to' | cumsum = 0.3380\n",
            "  02. '   not' | cumsum = 0.5358\n",
            "  03. '  that' | cumsum = 0.6082\n",
            "  04. '   the' | cumsum = 0.6651\n",
            "  05. '     a' | cumsum = 0.6900\n",
            "  06. '    in' | cumsum = 0.7139\n",
            "  07. ' finding' | cumsum = 0.7340\n",
            "  08. ' knowing' | cumsum = 0.7506\n",
            "\n",
            "(3) Nucleus cutoff at p = 0.99\n",
            "Tokens KEPT in nucleus (15 tokens): [' to', ' not', ' that', ' the', ' a', ' in', ' finding', ' knowing', ' love', ' being', ' self', ' understanding', ' always', ' simple', ' making']\n",
            "Tokens REMOVED: []\n",
            "Tokens removed by top-p (p=0.99): [' pay', ' tied', ' instant', ' cultivated', ' asserting', ' conscientious', ' rewarding', ' utilizing', ' birth', ' distraction']...\n",
            "Total tokens kept in nucleus (sum p <= 0.99): 1337\n",
            "\n",
            "(4) Renormalization:\n",
            "Sum of probs before renorm = 0.9900\n",
            "Renormalized nucleus probabilities:\n",
            "  '    to' | prob = 0.3414\n",
            "  '   not' | prob = 0.1998\n",
            "  '  that' | prob = 0.0732\n",
            "  '   the' | prob = 0.0575\n",
            "  '     a' | prob = 0.0251\n",
            "  '    in' | prob = 0.0242\n",
            "  ' finding' | prob = 0.0203\n",
            "  ' knowing' | prob = 0.0168\n",
            "  '  love' | prob = 0.0115\n",
            "  ' being' | prob = 0.0093\n",
            "  '  self' | prob = 0.0068\n",
            "  ' understanding' | prob = 0.0066\n",
            "  ' always' | prob = 0.0064\n",
            "  ' simple' | prob = 0.0062\n",
            "  ' making' | prob = 0.0059\n",
            "\n",
            "(1) After sorting probabilities (descending):\n",
            "  01. '    in' | prob = 0.3226\n",
            "  02. '  that' | prob = 0.0935\n",
            "  03. '     .' | prob = 0.0784\n",
            "  04. '  with' | prob = 0.0615\n",
            "  05. ' without' | prob = 0.0600\n",
            "\n",
            "Step 2 - BEFORE top-p\n",
            "\n",
            "(2) Cumulative probability mass:\n",
            "  01. '    in' | cumsum = 0.3226\n",
            "  02. '  that' | cumsum = 0.4161\n",
            "  03. '     .' | cumsum = 0.4945\n",
            "  04. '  with' | cumsum = 0.5560\n",
            "  05. ' without' | cumsum = 0.6160\n",
            "  06. ' itself' | cumsum = 0.6640\n",
            "  07. '    is' | cumsum = 0.7058\n",
            "  08. ' alone' | cumsum = 0.7405\n",
            "\n",
            "(3) Nucleus cutoff at p = 0.99\n",
            "Tokens KEPT in nucleus (15 tokens): [' in', ' that', '.', ' with', ' without', ' itself', ' is', ' alone', ',', ' for', ' of', ' not', ' and', ' from', ' at']\n",
            "Tokens REMOVED: []\n",
            "Tokens removed by top-p (p=0.99): [' eating', ' occurs', ' led', ' worth', ' spread', ' hard', ' creating', ' running', ' experience', ' did']...\n",
            "Total tokens kept in nucleus (sum p <= 0.99): 346\n",
            "\n",
            "(4) Renormalization:\n",
            "Sum of probs before renorm = 0.9900\n",
            "Renormalized nucleus probabilities:\n",
            "  '    in' | prob = 0.3258\n",
            "  '  that' | prob = 0.0944\n",
            "  '     .' | prob = 0.0792\n",
            "  '  with' | prob = 0.0622\n",
            "  ' without' | prob = 0.0606\n",
            "  ' itself' | prob = 0.0484\n",
            "  '    is' | prob = 0.0423\n",
            "  ' alone' | prob = 0.0350\n",
            "  '     ,' | prob = 0.0314\n",
            "  '   for' | prob = 0.0174\n",
            "  '    of' | prob = 0.0123\n",
            "  '   not' | prob = 0.0113\n",
            "  '   and' | prob = 0.0105\n",
            "  '  from' | prob = 0.0096\n",
            "  '    at' | prob = 0.0090\n",
            "\n",
            "(1) After sorting probabilities (descending):\n",
            "  01. '   the' | prob = 0.2501\n",
            "  02. ' yourself' | prob = 0.1824\n",
            "  03. ' itself' | prob = 0.1031\n",
            "  04. '   its' | prob = 0.0725\n",
            "  05. '  your' | prob = 0.0707\n",
            "\n",
            "Step 3 - BEFORE top-p\n",
            "\n",
            "(2) Cumulative probability mass:\n",
            "  01. '   the' | cumsum = 0.2501\n",
            "  02. ' yourself' | cumsum = 0.4325\n",
            "  03. ' itself' | cumsum = 0.5356\n",
            "  04. '   its' | cumsum = 0.6081\n",
            "  05. '  your' | cumsum = 0.6788\n",
            "  06. ' oneself' | cumsum = 0.7336\n",
            "  07. '     a' | cumsum = 0.7608\n",
            "  08. '   all' | cumsum = 0.7796\n",
            "\n",
            "(3) Nucleus cutoff at p = 0.99\n",
            "Tokens KEPT in nucleus (15 tokens): [' the', ' yourself', ' itself', ' its', ' your', ' oneself', ' a', ' all', ' ourselves', ' being', ' action', ' one', ' life', ' our', ' every']\n",
            "Tokens REMOVED: []\n",
            "Tokens removed by top-p (p=0.99): [' values', ' confrontation', ' song', ' letter', ' conscience', ' pur', ' LOVE', ' labor', ' quest', ' G']...\n",
            "Total tokens kept in nucleus (sum p <= 0.99): 772\n",
            "\n",
            "(4) Renormalization:\n",
            "Sum of probs before renorm = 0.9900\n",
            "Renormalized nucleus probabilities:\n",
            "  '   the' | prob = 0.2526\n",
            "  ' yourself' | prob = 0.1843\n",
            "  ' itself' | prob = 0.1041\n",
            "  '   its' | prob = 0.0732\n",
            "  '  your' | prob = 0.0714\n",
            "  ' oneself' | prob = 0.0554\n",
            "  '     a' | prob = 0.0274\n",
            "  '   all' | prob = 0.0190\n",
            "  ' ourselves' | prob = 0.0189\n",
            "  ' being' | prob = 0.0144\n",
            "  ' action' | prob = 0.0117\n",
            "  '   one' | prob = 0.0107\n",
            "  '  life' | prob = 0.0079\n",
            "  '   our' | prob = 0.0076\n",
            "  ' every' | prob = 0.0061\n",
            "\n",
            "(1) After sorting probabilities (descending):\n",
            "  01. '     .' | prob = 0.5960\n",
            "  02. '     ,' | prob = 0.1586\n",
            "  03. '   and' | prob = 0.1283\n",
            "  04. '    .\"' | prob = 0.0327\n",
            "  05. '    ,\"' | prob = 0.0135\n",
            "\n",
            "Step 4 - BEFORE top-p\n",
            "\n",
            "(2) Cumulative probability mass:\n",
            "  01. '     .' | cumsum = 0.5960\n",
            "  02. '     ,' | cumsum = 0.7546\n",
            "  03. '   and' | cumsum = 0.8829\n",
            "  04. '    .\"' | cumsum = 0.9156\n",
            "  05. '    ,\"' | cumsum = 0.9291\n",
            "  06. '     ;' | cumsum = 0.9416\n",
            "  07. '     \n",
            "' | cumsum = 0.9495\n",
            "  08. '     !' | cumsum = 0.9568\n",
            "\n",
            "(3) Nucleus cutoff at p = 0.99\n",
            "Tokens KEPT in nucleus (15 tokens): ['.', ',', ' and', '.\"', ',\"', ';', '\\n', '!', ':', ' —', ' -', ' –', ' as', ' or', ' .']\n",
            "Tokens REMOVED: []\n",
            "Tokens removed by top-p (p=0.99): ['\",', ' ,', ' rather', ' not', '?', '-', ' to', '/', ' but', ' instead']...\n",
            "Total tokens kept in nucleus (sum p <= 0.99): 32\n",
            "\n",
            "(4) Renormalization:\n",
            "Sum of probs before renorm = 0.9902\n",
            "Renormalized nucleus probabilities:\n",
            "  '     .' | prob = 0.6019\n",
            "  '     ,' | prob = 0.1601\n",
            "  '   and' | prob = 0.1296\n",
            "  '    .\"' | prob = 0.0330\n",
            "  '    ,\"' | prob = 0.0136\n",
            "  '     ;' | prob = 0.0126\n",
            "  '     \n",
            "' | prob = 0.0080\n",
            "  '     !' | prob = 0.0074\n",
            "  '     :' | prob = 0.0036\n",
            "  '     —' | prob = 0.0035\n",
            "  '     -' | prob = 0.0033\n",
            "  '     –' | prob = 0.0030\n",
            "  '    as' | prob = 0.0025\n",
            "  '    or' | prob = 0.0023\n",
            "  '     .' | prob = 0.0022\n",
            "The secret to happiness is happiness in yourself and\n"
          ]
        }
      ],
      "source": [
        "def top_p_decode(prompt: str, p: float = 0.9, temperature: float = 1.0, max_new_tokens: int = 50) -> str:\n",
        "    \"\"\"\n",
        "    Top-p (nucleus) sampling: sample from smallest set with cumulative prob >= p.\n",
        "\n",
        "    Algorithm:\n",
        "    1. Get logits and convert to probabilities\n",
        "    2. Sort probabilities in descending order\n",
        "    3. Compute cumulative sum\n",
        "    4. Find cutoff where cumsum >= p\n",
        "    5. Keep only tokens up to cutoff\n",
        "    6. Renormalize and sample\n",
        "    \"\"\"\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "    generated_ids = input_ids[0].tolist()\n",
        "\n",
        "    for step in range(max_new_tokens):\n",
        "        input_tensor = torch.tensor([generated_ids]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_tensor)\n",
        "            logits = outputs.logits[0, -1, :]\n",
        "\n",
        "        # Apply temperature first\n",
        "        scaled_logits = logits / temperature\n",
        "\n",
        "        # Convert to probabilities\n",
        "        probs = F.softmax(scaled_logits, dim=-1)\n",
        "\n",
        "        # TOP-P: Sort probabilities descending\n",
        "        sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
        "\n",
        "        #vizualizing the desending probs\n",
        "        print(\"\\n(1) After sorting probabilities (descending):\")\n",
        "        for i in range(5):\n",
        "              token = tokenizer.decode([sorted_indices[i]])\n",
        "              print(f\"  {i+1:02d}. '{token:>6}' | prob = {sorted_probs[i]:.4f}\")\n",
        "\n",
        "        topk_probs, topk_indices = torch.topk(probs, 3)\n",
        "        print(f\"\\nStep {step+1} - BEFORE top-p\")\n",
        "        for i, idx in enumerate(topk_indices):\n",
        "            token = tokenizer.decode([idx])\n",
        "\n",
        "        # Compute cumulative sum\n",
        "        cumsum_probs = torch.cumsum(sorted_probs, dim=-1)\n",
        "\n",
        "        # Cumsum_probs added to show better vizualiztion\n",
        "        print(\"\\n(2) Cumulative probability mass:\")\n",
        "        for i in range(8):\n",
        "            token = tokenizer.decode([sorted_indices[i]])\n",
        "            print(f\"  {i+1:02d}. '{token:>6}' | cumsum = {cumsum_probs[i]:.4f}\")\n",
        "\n",
        "        # Find cutoff: where cumsum first exceeds p\n",
        "        # We want to KEEP tokens where cumsum <= p (plus the first one that exceeds)\n",
        "        sorted_indices_to_remove = cumsum_probs > p\n",
        "\n",
        "        # Shift right to keep the first token that exceeds p\n",
        "        sorted_indices_to_remove[1:] = sorted_indices_to_remove[:-1].clone()\n",
        "        sorted_indices_to_remove[0] = False\n",
        "\n",
        "        # Lets have a look at retained nucules\n",
        "        nucleus_tokens = []\n",
        "        removed_tokens = []\n",
        "\n",
        "        for i, remove in enumerate(sorted_indices_to_remove[:15]):\n",
        "            token = tokenizer.decode([sorted_indices[i]])\n",
        "            if remove:\n",
        "                removed_tokens.append(token)\n",
        "            else:\n",
        "                nucleus_tokens.append(token)\n",
        "\n",
        "        print(f\"\\n(3) Nucleus cutoff at p = {p}\")\n",
        "        print(f\"Tokens KEPT in nucleus ({len(nucleus_tokens)} tokens): {nucleus_tokens}\")\n",
        "        print(f\"Tokens REMOVED: {removed_tokens[:10]}{'...' if len(removed_tokens) > 10 else ''}\")\n",
        "\n",
        "\n",
        "        # Set removed tokens to 0 probability\n",
        "        sorted_probs[sorted_indices_to_remove] = 0\n",
        "\n",
        "        # List of removed tail of tokens\n",
        "        removed_tokens = [tokenizer.decode([sorted_indices[i]])\n",
        "                      for i, remove in enumerate(sorted_indices_to_remove) if remove]\n",
        "        print(f\"Tokens removed by top-p (p={p}): {removed_tokens[:10]}{'...' if len(removed_tokens)>10 else ''}\")\n",
        "\n",
        "        # Calculate and print the number of tokens kept\n",
        "        num_tokens_kept = (~sorted_indices_to_remove).sum().item()\n",
        "        print(f\"Total tokens kept in nucleus (sum p <= {p}): {num_tokens_kept}\")\n",
        "\n",
        "        # Store sum of probabilities before renormalization\n",
        "        prob_sum_before = sorted_probs.sum().item()\n",
        "\n",
        "        # Renormalize\n",
        "        sorted_probs = sorted_probs / sorted_probs.sum()\n",
        "\n",
        "        # to vizualse after renomalize\n",
        "        print(\"\\n(4) Renormalization:\")\n",
        "        print(f\"Sum of probs before renorm = {prob_sum_before:.4f}\")\n",
        "        print(\"Renormalized nucleus probabilities:\")\n",
        "        for i in range(len(nucleus_tokens)):\n",
        "            token = tokenizer.decode([sorted_indices[i]])\n",
        "            print(f\"  '{token:>6}' | prob = {sorted_probs[i]:.4f}\")\n",
        "\n",
        "        # Create full probability tensor\n",
        "        filtered_probs = torch.zeros_like(probs)\n",
        "        filtered_probs[sorted_indices] = sorted_probs\n",
        "\n",
        "        # Sample\n",
        "        next_token_id = torch.multinomial(filtered_probs, num_samples=1).item()\n",
        "\n",
        "        generated_ids.append(next_token_id)\n",
        "\n",
        "        if next_token_id == tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "    return tokenizer.decode(generated_ids)\n",
        "\n",
        "# Compare different p values\n",
        "prompt = \"The secret to happiness is\"\n",
        "print(f\"Prompt: '{prompt}'\\n\")\n",
        "\n",
        "for p_val in [0.5, 0.8, 0.95, 0.99]:\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"TOP-P = {p_val}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    output = top_p_decode(prompt, p=p_val, temperature=0.8, max_new_tokens=4)\n",
        "    #print(output)\n",
        "    print(textwrap.fill(output, width=70))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beam-header",
      "metadata": {
        "id": "beam-header"
      },
      "source": [
        "---\n",
        "## Strategy 4: Beam Search\n",
        "\n",
        "**Idea**: Track multiple candidate sequences (\"beams\") and keep the best ones.\n",
        "\n",
        "```\n",
        "Step 1: Start with n beams, each with the prompt\n",
        "Step 2: For each beam, get top-k next tokens\n",
        "Step 3: Score all (beam × token) combinations\n",
        "Step 4: Keep top n combinations as new beams\n",
        "Step 5: Repeat until done\n",
        "```\n",
        "\n",
        "**Scoring**: Usually sum of log-probabilities (higher = better)\n",
        "\n",
        "**Pros**: Finds higher probability sequences  \n",
        "**Cons**: Slower, can be repetitive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question: Beam Search vs Sampling Compare the beam search output with greedy decoding output for the same prompt. Explain how beam search maintains multiple hypotheses and why this can find higher-probability sequences than greedy. What is the tradeoff between beam search and sampling-based methods (temperature/top-p) in terms of output diversity and quality?"
      ],
      "metadata": {
        "id": "CpvJ50RlcGOQ"
      },
      "id": "CpvJ50RlcGOQ"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "beam",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "beam",
        "outputId": "96ae3a46-a9d4-422c-cc6c-461613d9c158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "GREEDY:\n",
            "==================================================\n",
            "The quick brown foxes are a great way to\n",
            "\n",
            "==================================================\n",
            "BEAM SEARCH (num_beams=3):\n",
            "--------------------------------------------------\n",
            "\n",
            "----------------------------------\n",
            "STEP 1\n",
            "----------------------------------\n",
            "\n",
            "Current beam:\n",
            "The quick brown fox\n",
            "Top next-token choices:\n",
            "  Token: 'es' | logP = -2.04\n",
            "  Token: ' was' | logP = -3.09\n",
            "  Token: ' is' | logP = -3.37\n",
            "  Token: \"'s\" | logP = -3.41\n",
            "  Token: ',' | logP = -3.46\n",
            "  Token: ' that' | logP = -3.81\n",
            "\n",
            "Top beams:\n",
            "Beam 1 | Score: -2.04\n",
            "The quick brown foxes\n",
            "Beam 2 | Score: -3.09\n",
            "The quick brown fox was\n",
            "Beam 3 | Score: -3.37\n",
            "The quick brown fox is\n",
            "\n",
            "----------------------------------\n",
            "STEP 2\n",
            "----------------------------------\n",
            "\n",
            "Current beam:\n",
            "The quick brown foxes\n",
            "Top next-token choices:\n",
            "  Token: ' are' | logP = -2.32\n",
            "  Token: ',' | logP = -2.79\n",
            "  Token: ' were' | logP = -2.89\n",
            "  Token: ' that' | logP = -3.07\n",
            "  Token: ' have' | logP = -3.39\n",
            "  Token: ' and' | logP = -3.42\n",
            "\n",
            "Current beam:\n",
            "The quick brown fox was\n",
            "Top next-token choices:\n",
            "  Token: ' a' | logP = -3.12\n",
            "  Token: ' the' | logP = -4.04\n",
            "  Token: ' about' | logP = -4.20\n",
            "  Token: ' not' | logP = -4.27\n",
            "  Token: ' still' | logP = -4.31\n",
            "  Token: ' so' | logP = -4.32\n",
            "\n",
            "Current beam:\n",
            "The quick brown fox is\n",
            "Top next-token choices:\n",
            "  Token: ' a' | logP = -2.10\n",
            "  Token: ' the' | logP = -3.18\n",
            "  Token: ' an' | logP = -3.82\n",
            "  Token: ' not' | logP = -3.90\n",
            "  Token: ' also' | logP = -3.94\n",
            "  Token: ' now' | logP = -4.06\n",
            "\n",
            "Top beams:\n",
            "Beam 1 | Score: -4.36\n",
            "The quick brown foxes are\n",
            "Beam 2 | Score: -4.83\n",
            "The quick brown foxes,\n",
            "Beam 3 | Score: -4.93\n",
            "The quick brown foxes were\n",
            "\n",
            "----------------------------------\n",
            "STEP 3\n",
            "----------------------------------\n",
            "\n",
            "Current beam:\n",
            "The quick brown foxes are\n",
            "Top next-token choices:\n",
            "  Token: ' a' | logP = -2.99\n",
            "  Token: ' the' | logP = -3.06\n",
            "  Token: ' also' | logP = -3.49\n",
            "  Token: ' not' | logP = -3.72\n",
            "  Token: ' very' | logP = -3.85\n",
            "  Token: ' known' | logP = -4.16\n",
            "\n",
            "Current beam:\n",
            "The quick brown foxes,\n",
            "Top next-token choices:\n",
            "  Token: ' which' | logP = -2.56\n",
            "  Token: ' who' | logP = -2.83\n",
            "  Token: ' the' | logP = -3.17\n",
            "  Token: ' with' | logP = -3.40\n",
            "  Token: ' they' | logP = -3.93\n",
            "  Token: ' and' | logP = -3.94\n",
            "\n",
            "Current beam:\n",
            "The quick brown foxes were\n",
            "Top next-token choices:\n",
            "  Token: ' the' | logP = -3.55\n",
            "  Token: ' a' | logP = -3.73\n",
            "  Token: ' also' | logP = -3.84\n",
            "  Token: ' not' | logP = -3.88\n",
            "  Token: ' able' | logP = -4.28\n",
            "  Token: ' so' | logP = -4.33\n",
            "\n",
            "Top beams:\n",
            "Beam 1 | Score: -7.35\n",
            "The quick brown foxes are a\n",
            "Beam 2 | Score: -7.39\n",
            "The quick brown foxes, which\n",
            "Beam 3 | Score: -7.42\n",
            "The quick brown foxes are the\n",
            "\n",
            "----------------------------------\n",
            "STEP 4\n",
            "----------------------------------\n",
            "\n",
            "Current beam:\n",
            "The quick brown foxes are a\n",
            "Top next-token choices:\n",
            "  Token: ' great' | logP = -3.13\n",
            "  Token: ' bit' | logP = -3.23\n",
            "  Token: ' common' | logP = -3.38\n",
            "  Token: ' good' | logP = -3.43\n",
            "  Token: ' little' | logP = -3.57\n",
            "  Token: ' very' | logP = -3.58\n",
            "\n",
            "Current beam:\n",
            "The quick brown foxes, which\n",
            "Top next-token choices:\n",
            "  Token: ' are' | logP = -1.58\n",
            "  Token: ' have' | logP = -2.73\n",
            "  Token: ' were' | logP = -3.09\n",
            "  Token: ' can' | logP = -3.38\n",
            "  Token: ' had' | logP = -3.78\n",
            "  Token: ' live' | logP = -3.90\n",
            "\n",
            "Current beam:\n",
            "The quick brown foxes are the\n",
            "Top next-token choices:\n",
            "  Token: ' most' | logP = -1.93\n",
            "  Token: ' best' | logP = -2.53\n",
            "  Token: ' only' | logP = -3.01\n",
            "  Token: ' ones' | logP = -3.87\n",
            "  Token: ' first' | logP = -3.95\n",
            "  Token: ' same' | logP = -4.05\n",
            "\n",
            "Top beams:\n",
            "Beam 1 | Score: -8.97\n",
            "The quick brown foxes, which are\n",
            "Beam 2 | Score: -9.35\n",
            "The quick brown foxes are the most\n",
            "Beam 3 | Score: -9.95\n",
            "The quick brown foxes are the best\n",
            "\n",
            "----------------------------------\n",
            "STEP 5\n",
            "----------------------------------\n",
            "\n",
            "Current beam:\n",
            "The quick brown foxes, which are\n",
            "Top next-token choices:\n",
            "  Token: ' known' | logP = -3.45\n",
            "  Token: ' the' | logP = -3.62\n",
            "  Token: ' usually' | logP = -3.65\n",
            "  Token: ' also' | logP = -3.70\n",
            "  Token: ' often' | logP = -3.72\n",
            "  Token: ' found' | logP = -3.87\n",
            "\n",
            "Current beam:\n",
            "The quick brown foxes are the most\n",
            "Top next-token choices:\n",
            "  Token: ' common' | logP = -2.08\n",
            "  Token: ' popular' | logP = -3.08\n",
            "  Token: ' aggressive' | logP = -3.57\n",
            "  Token: ' dangerous' | logP = -3.87\n",
            "  Token: ' important' | logP = -4.06\n",
            "  Token: ' likely' | logP = -4.18\n",
            "\n",
            "Current beam:\n",
            "The quick brown foxes are the best\n",
            "Top next-token choices:\n",
            "  Token: ' at' | logP = -2.79\n",
            "  Token: ' of' | logP = -2.89\n",
            "  Token: '.' | logP = -2.95\n",
            "  Token: ' for' | logP = -3.29\n",
            "  Token: ' in' | logP = -3.55\n",
            "  Token: ',' | logP = -3.56\n",
            "\n",
            "Top beams:\n",
            "Beam 1 | Score: -11.43\n",
            "The quick brown foxes are the most common\n",
            "Beam 2 | Score: -12.42\n",
            "The quick brown foxes, which are known\n",
            "Beam 3 | Score: -12.44\n",
            "The quick brown foxes are the most popular\n",
            "\n",
            "----------------------------------\n",
            "STEP 6\n",
            "----------------------------------\n",
            "\n",
            "Current beam:\n",
            "The quick brown foxes are the most common\n",
            "Top next-token choices:\n",
            "  Token: ' species' | logP = -2.60\n",
            "  Token: ' of' | logP = -2.77\n",
            "  Token: ' fox' | logP = -3.17\n",
            "  Token: ' type' | logP = -3.17\n",
            "  Token: ' and' | logP = -3.59\n",
            "  Token: '.' | logP = -3.69\n",
            "\n",
            "Current beam:\n",
            "The quick brown foxes, which are known\n",
            "Top next-token choices:\n",
            "  Token: ' to' | logP = -0.89\n",
            "  Token: ' for' | logP = -1.07\n",
            "  Token: ' as' | logP = -1.89\n",
            "  Token: ' in' | logP = -3.62\n",
            "  Token: ' by' | logP = -4.85\n",
            "  Token: ' from' | logP = -4.92\n",
            "\n",
            "Current beam:\n",
            "The quick brown foxes are the most popular\n",
            "Top next-token choices:\n",
            "  Token: ' of' | logP = -2.40\n",
            "  Token: '.' | logP = -2.87\n",
            "  Token: ' species' | logP = -3.00\n",
            "  Token: ',' | logP = -3.18\n",
            "  Token: ' and' | logP = -3.19\n",
            "  Token: ' fox' | logP = -3.46\n",
            "\n",
            "Top beams:\n",
            "Beam 1 | Score: -13.32\n",
            "The quick brown foxes, which are known to\n",
            "Beam 2 | Score: -13.50\n",
            "The quick brown foxes, which are known for\n",
            "Beam 3 | Score: -14.03\n",
            "The quick brown foxes are the most common species\n",
            "The quick brown foxes, which are known to\n"
          ]
        }
      ],
      "source": [
        "def beam_search_decode(prompt: str, num_beams: int = 3, max_new_tokens: int = 50) -> str:\n",
        "    \"\"\"\n",
        "    Beam search: track multiple candidate sequences.\n",
        "\n",
        "    Each beam is a tuple: (token_ids, cumulative_log_prob)\n",
        "\n",
        "    Algorithm:\n",
        "    1. Start with one beam containing the prompt\n",
        "    2. For each beam, get log-probs for all next tokens\n",
        "    3. Consider all (beam, next_token) combinations\n",
        "    4. Keep top num_beams combinations as new beams\n",
        "    5. Repeat until done\n",
        "    \"\"\"\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "    initial_ids = input_ids[0].tolist()\n",
        "\n",
        "    # Initialize beams: (token_ids, cumulative_log_prob)\n",
        "    beams = [(initial_ids, 0.0)]\n",
        "    completed_beams = []\n",
        "\n",
        "    # Adding steps for clear token by token breakdown\n",
        "    for step in range(max_new_tokens):\n",
        "        print(\"\\n----------------------------------\")\n",
        "        print(f\"STEP {step + 1}\")\n",
        "        print(\"----------------------------------\")\n",
        "        all_candidates = []\n",
        "\n",
        "        for beam_ids, beam_score in beams:\n",
        "            # Skip if this beam is already complete\n",
        "            if beam_ids[-1] == tokenizer.eos_token_id:\n",
        "                completed_beams.append((beam_ids, beam_score))\n",
        "                continue\n",
        "\n",
        "            # Get next token probabilities\n",
        "            input_tensor = torch.tensor([beam_ids]).to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input_tensor)\n",
        "                logits = outputs.logits[0, -1, :]\n",
        "\n",
        "            # Convert to log-probabilities\n",
        "            log_probs = F.log_softmax(logits, dim=-1)\n",
        "\n",
        "            print(\"\\nCurrent beam:\")\n",
        "            print(tokenizer.decode(beam_ids))\n",
        "            print(\"Top next-token choices:\")\n",
        "\n",
        "            # Get top candidates for this beam\n",
        "            top_log_probs, top_indices = torch.topk(log_probs, num_beams * 2)\n",
        "\n",
        "            for log_prob, idx in zip(top_log_probs, top_indices):\n",
        "                new_ids = beam_ids + [idx.item()]\n",
        "                new_score = beam_score + log_prob.item()\n",
        "                all_candidates.append((new_ids, new_score))\n",
        "                print(f\"  Token: {tokenizer.decode([idx])!r} | logP = {log_prob:.2f}\")\n",
        "\n",
        "        # If no active candidates, we're done\n",
        "        if not all_candidates:\n",
        "            break\n",
        "\n",
        "        # Keep top num_beams candidates\n",
        "        all_candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "        beams = all_candidates[:num_beams]\n",
        "\n",
        "        print(\"\\nTop beams:\")\n",
        "        for i, (tokens, score) in enumerate(beams):\n",
        "            text = tokenizer.decode(tokens)\n",
        "            print(f\"Beam {i+1} | Score: {score:.2f}\")\n",
        "            print(text)\n",
        "\n",
        "\n",
        "    # Add remaining beams to completed\n",
        "    completed_beams.extend(beams)\n",
        "\n",
        "    # Return best beam (highest score)\n",
        "    best_beam = max(completed_beams, key=lambda x: x[1])\n",
        "    return tokenizer.decode(best_beam[0])\n",
        "\n",
        "# Test beam search\n",
        "prompt = \"The quick brown fox\"\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"GREEDY:\")\n",
        "print(\"=\"*50)\n",
        "print(greedy_decode(prompt, max_new_tokens=6))\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"BEAM SEARCH (num_beams=3):\")\n",
        "print(f\"{'-'*50}\")\n",
        "print(beam_search_decode(prompt, num_beams=3, max_new_tokens=6))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}